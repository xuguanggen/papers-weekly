#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯å‘¨è®ºæ–‡çˆ¬è™« - æ”¯æŒå¤šæ—¥æœŸå­˜æ¡£
"""

import json
import os
from datetime import datetime
import shutil

def create_weekly_archive():
    """åˆ›å»ºæœ¬å‘¨çš„è®ºæ–‡å­˜æ¡£"""
    
    # è·å–å½“å‰æ—¥æœŸ
    current_date = datetime.now().strftime('%Y-%m-%d')
    current_week = datetime.now().strftime('%Y-W%W')  # ä¾‹å¦‚: 2026-W07
    
    # åˆ›å»ºå­˜æ¡£ç›®å½•
    archive_dir = "/data/workspace/papers-weekly-site/archives"
    os.makedirs(archive_dir, exist_ok=True)
    
    # è¯»å–æ‰€æœ‰è®ºæ–‡æ•°æ® (ä½¿ç”¨ä¿®å¤åçš„æ•°æ®æº)
    data_file = '/data/workspace/papers_data_fixed.json'
    if not os.path.exists(data_file):
        data_file = '/data/workspace/papers_data.json'
    
    with open(data_file, 'r', encoding='utf-8') as f:
        all_papers = json.load(f)
    
    # ç¡®ä¿æ‰€æœ‰è®ºæ–‡éƒ½æœ‰URL
    import re
    for paper in all_papers:
        if not paper.get('url') or paper['url'] == 'å¾…è·å–':
            arxiv_id = paper.get('arxiv_id', '')
            if arxiv_id:
                clean_id = re.sub(r'v\d+$', '', arxiv_id)
                paper['url'] = f'https://arxiv.org/abs/{clean_id}'
    
    print(f"ğŸ“š æ‰¾åˆ° {len(all_papers)} ç¯‡è®ºæ–‡")
    
    # åˆ›å»ºæœ¬å‘¨å­˜æ¡£
    archive_data = {
        'date': current_date,
        'week': current_week,
        'count': len(all_papers),
        'papers': all_papers
    }
    
    # ä¿å­˜åˆ°å­˜æ¡£æ–‡ä»¶
    archive_file = f"{archive_dir}/{current_week}.json"
    with open(archive_file, 'w', encoding='utf-8') as f:
        json.dump(archive_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²åˆ›å»ºå­˜æ¡£: {archive_file}")
    
    # æ›´æ–°ç´¢å¼•æ–‡ä»¶
    index_file = f"{archive_dir}/index.json"
    if os.path.exists(index_file):
        with open(index_file, 'r', encoding='utf-8') as f:
            index = json.load(f)
    else:
        index = {'archives': []}
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥å‘¨çš„å­˜æ¡£
    existing = [a for a in index['archives'] if a['week'] == current_week]
    if existing:
        # æ›´æ–°ç°æœ‰å­˜æ¡£
        for a in index['archives']:
            if a['week'] == current_week:
                a['date'] = current_date
                a['count'] = len(all_papers)
        print(f"ğŸ”„ æ›´æ–°å­˜æ¡£: {current_week}")
    else:
        # æ·»åŠ æ–°å­˜æ¡£
        index['archives'].insert(0, {
            'week': current_week,
            'date': current_date,
            'count': len(all_papers)
        })
        print(f"â• æ·»åŠ æ–°å­˜æ¡£: {current_week}")
    
    # ä¿å­˜ç´¢å¼•
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç´¢å¼•å·²æ›´æ–°")
    return archive_data

if __name__ == "__main__":
    create_weekly_archive()
