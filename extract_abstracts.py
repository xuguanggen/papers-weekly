#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®ºæ–‡æ‘˜è¦ç¿»è¯‘è„šæœ¬ - ç¦»çº¿ç‰ˆæœ¬
æå–æ‰€æœ‰è‹±æ–‡æ‘˜è¦ï¼Œå‡†å¤‡æ‰¹é‡ç¿»è¯‘
"""

import re
import json

def extract_abstracts_with_positions(html_content):
    """ä»HTMLä¸­æå–æ‰€æœ‰æ‘˜è¦åŠå…¶ä½ç½®ä¿¡æ¯"""
    pattern = r'<div class="summary-text">(.*?)</div>'
    abstracts = []
    for match in re.finditer(pattern, html_content, re.DOTALL):
        abstracts.append({
            'text': match.group(1).strip(),
            'start': match.start(1),
            'end': match.end(1)
        })
    return abstracts

def main():
    input_file = "/data/workspace/papers-weekly-site/index.html"
    
    # è¯»å–HTMLæ–‡ä»¶
    with open(input_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    # æå–æ‰€æœ‰æ‘˜è¦
    abstracts = extract_abstracts_with_positions(html_content)
    print(f"æ‰¾åˆ° {len(abstracts)} ç¯‡è®ºæ–‡æ‘˜è¦")
    
    # å¯¼å‡ºä¸ºJSONæ ¼å¼ï¼Œæ–¹ä¾¿ç¿»è¯‘
    output_data = []
    for i, abstract in enumerate(abstracts, 1):
        output_data.append({
            'id': i,
            'english': abstract['text'],
            'chinese': ''  # å¾…ç¿»è¯‘
        })
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open('/data/workspace/papers-weekly-site/abstracts.json', 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²å¯¼å‡ºæ‘˜è¦åˆ° abstracts.json")
    print(f"ğŸ“ å…± {len(abstracts)} ç¯‡æ‘˜è¦å¾…ç¿»è¯‘")
    
    # æ‰“å°å‰3ç¯‡ä½œä¸ºé¢„è§ˆ
    print("\nå‰3ç¯‡æ‘˜è¦é¢„è§ˆ:")
    for item in output_data[:3]:
        print(f"\n--- ç¬¬{item['id']}ç¯‡ ---")
        print(f"{item['english'][:200]}...")

if __name__ == "__main__":
    main()
