{
  "date": "2026-02-11",
  "week": "2026-W06",
  "count": 155,
  "papers": [
    {
      "arxiv_id": "2602.07085",
      "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
      "authors": "Jun Han, Shuo Zhang, Wei Li 等",
      "summary": "金融市场充满噪声且非平稳，这使得alpha挖掘对回测结果中的噪声和突发的市场制度转变高度敏感。为应对这一挑战，我们提出了QuantaAlpha，一个专为LLM驱动的alpha挖掘设计的演化框架。",
      "url": "https://arxiv.org/abs/2602.07085",
      "abstract": "金融市场充满噪声且非平稳，这使得alpha挖掘对回测结果中的噪声和突发的市场制度转变高度敏感。为应对这一挑战，我们提出了QuantaAlpha，一个专为LLM驱动的alpha挖掘设计的演化框架。"
    },
    {
      "arxiv_id": "2602.08222",
      "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
      "authors": "Zehao Chen, Gongxun Li, Tianxiang Ai 等",
      "summary": "随着后训练优化成为改进大型语言模型的核心，我们观察到一个持续的饱和瓶颈。本文介绍了弱驱动学习（WDL），这是一种利用弱智能体加速强智能体改进的范式。",
      "url": "https://arxiv.org/abs/2602.08222",
      "abstract": "随着后训练优化成为改进大型语言模型的核心，我们观察到一个持续的饱和瓶颈。本文介绍了弱驱动学习（WDL），这是一种利用弱智能体加速强智能体改进的范式。"
    },
    {
      "arxiv_id": "2602.08794",
      "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
      "authors": "Yuxuan Wang, Ziyang Yuan, Ruiqing Ma 等",
      "summary": "扩散模型的最新进展显著增强了视频和音频生成的质量。然而，现有的同步视频-音频生成方法在可扩展性、时间对齐和语义一致性方面存在局限性。",
      "url": "https://arxiv.org/abs/2602.08794",
      "abstract": "扩散模型的最新进展显著增强了视频和音频生成的质量。然而，现有的同步视频-音频生成方法在可扩展性、时间对齐和语义一致性方面存在局限性。"
    },
    {
      "arxiv_id": "2602.07026",
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07026",
      "abstract": "最近，扩散模型的进展显著提升了视频和音频生成的质量和多样性。尽管在视频到音频（V2A）合成方面取得了进展，但生成与复杂视觉场景精确同步的高保真音频仍然是一个挑战。我们提出了MOVA，一个适配器解耦联合训练框架，用于电影级的V2A生成。"
    },
    {
      "arxiv_id": "2602.05400",
      "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05400",
      "abstract": "后训练优化已成为改进大型语言模型（LLMs）的核心，我们观察到一个持续的饱和瓶颈——当使用强大提示或偏好数据时，复杂推理能力在某个点之后停止提升。我们引入了Weak-Driven Learning，一种新的训练策略，通过学习纠正弱响应来克服这一饱和现象。"
    },
    {
      "arxiv_id": "2602.09856",
      "title": "Code2World: A GUI World Model via Renderable Code Generation",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09856",
      "abstract": "DeepSeek-R1-Lite-Preview在关键基准测试中展示了与OpenAI-o1-preview相当的推理能力，但这是以训练和推理过程中极高的计算成本为代价的。在本报告中，我们介绍了一系列密集和混合专家（MoE）模型，参数规模从1.5B到671B不等，包括我们的旗舰模型DeepSeek-R1。"
    },
    {
      "arxiv_id": "2602.09082",
      "title": "UI-Venus-1.5 Technical Report",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09082",
      "abstract": "随着人类活动和环境变化导致极端天气事件日益频繁且不可预测，对先进气候模拟模型的需求比以往任何时候都更加迫切。机器学习（ML）模型的最新进展导致了基于ML的天气预报（MLWP）模型的开发，这些模型表现出令人印象深刻的预测准确性。"
    },
    {
      "arxiv_id": "2602.06717",
      "title": "F-GRPO: Don't Let Your Policy Learn the Obvious and Forget the Rare",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06717",
      "abstract": "大型语言模型（LLMs）在简单推理任务上表现出色，但在需要复杂多步推理的数学和科学问题上仍然存在困难。最近，人们对利用推理时计算来提高LLM推理能力的兴趣激增，并取得了令人印象深刻的实证结果。"
    },
    {
      "arxiv_id": "2602.07845",
      "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07845",
      "abstract": "大型语言模型（LLMs）越来越多地集成到日常工具中，例如搜索引擎、代码助手和写作助手，使它们更容易受到提示注入攻击的影响。我们提出了一个全面的分类法，涵盖了12种不同的提示注入攻击策略。"
    },
    {
      "arxiv_id": "2602.06855",
      "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06855",
      "abstract": "金融市场充满噪声且非平稳，这使得alpha挖掘对回测结果中的噪声和突发的市场制度转变高度敏感。在本文中，我们提出QuantaAlpha，一个新颖的量化投资框架，利用深度强化学习和大型语言模型（LLMs）来实现自适应的alpha挖掘。"
    },
    {
      "arxiv_id": "2602.06570",
      "title": "Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06570",
      "abstract": "视觉语言模型（VLMs）的最新进展导致了强大的文本到图像（T2I）生成器和多模态LLMs（MLLMs）的发展。尽管许多模型在多样化任务中表现出色，但它们在统一的评估协议下通常还未经过系统测试。"
    },
    {
      "arxiv_id": "2602.05843",
      "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05843",
      "abstract": "我们介绍了R1-Distill，这是一个使用合成数据蒸馏推理能力的开放框架。我们从DeepSeek-R1蒸馏到Llama-3.1-8B-Instruct和Llama-3.3-70B-Instruct，在关键推理基准测试中实现了显著的性能提升。"
    },
    {
      "arxiv_id": "2602.05027",
      "title": "AudioSAE: Towards Understanding of Audio-Processing Models with Sparse AutoEncoders",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05027",
      "abstract": "在摘要生成和代码生成领域，大型语言模型（LLMs）通常表现出平均性能，尽管它们在许多任务上表现出色。这些多样化的结果表明，LLMs生成的输出包含有价值的信息，但由于质量不一致而未能充分利用。"
    },
    {
      "arxiv_id": "2602.03392",
      "title": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.03392",
      "abstract": "Kolmogorov-Arnold网络（KANs）作为多层感知器（MLPs）的有前途替代品而出现，提供了更好的准确性和可解释性。然而，它们的计算效率仍然远不如高度优化的密集矩阵乘法。"
    },
    {
      "arxiv_id": "2602.08676",
      "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08676",
      "abstract": "多模态大型语言模型（MLLMs）彻底改变了视觉理解，在各种视觉任务中表现出色。尽管取得了成功，但现有的MLLMs主要专注于高层次的视觉理解，而忽略了低层次的视觉感知能力。"
    },
    {
      "arxiv_id": "2602.08234",
      "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08234",
      "abstract": "无参考图像质量评估（NR-IQA）仅从视觉内容推断感知质量，与人类判断保持一致。现有的基于深度学习的NR-IQA方法通常依赖于有限的标记数据，阻碍了它们的泛化能力。"
    },
    {
      "arxiv_id": "2602.08990",
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08990",
      "abstract": "大型语言模型（LLMs）已成为代码生成的强大工具。然而，在自动化程序修复中，模型通常被微调以产生补丁，但通常缺乏对故障或其代码的深入理解。"
    },
    {
      "arxiv_id": "2602.07837",
      "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07837",
      "abstract": "对LLMs的训练后对齐方法的最新进展已从基于人类反馈的强化学习（RLHF）发展到可扩展监督，最近又发展到推理能力的训练后对齐。我们深入研究不同对齐范式的机制。"
    },
    {
      "arxiv_id": "2602.06422",
      "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06422",
      "abstract": "物体跟踪是一个基础的计算机视觉问题，在许多应用中都很重要。多模态跟踪利用RGB和其他模态（例如深度、事件或语言）的互补信息来应对具有挑战性的跟踪场景。"
    },
    {
      "arxiv_id": "2602.00169",
      "title": "Towards Agentic Intelligence for Materials Science",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.00169",
      "abstract": "对抗样本在破坏神经网络的稳定性方面显示出显著的有效性。一种新兴的对抗攻击类别，称为语义对抗样本，已被证明比传统的Lp范数约束的扰动更隐蔽和实用。"
    },
    {
      "arxiv_id": "2602.09007",
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09007",
      "abstract": "我们提出GEBench，这是一个将图像生成模型重新定位为GUI环境的新基准。与传统的以图像质量为中心的评估不同，GEBench将生成模型作为交互式环境进行测试，代理在其中采取行动（提供提示或编辑）并观察视觉反馈。这种范式能够评估视觉编辑能力、提示遵循性和生成模型内的多轮交互。"
    },
    {
      "arxiv_id": "2602.09443",
      "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09443",
      "abstract": "科学推理对现代大型视觉语言模型（LVLMs）构成了独特的挑战，因为它们必须整合复杂的视觉信息和先进的推理技能。尽管LVLMs在一般视觉理解任务中表现出色，但它们在科学推理的关键方面仍存在局限性。本文介绍P1-VL，一个旨在弥合视觉感知与科学推理之间差距的新框架。"
    },
    {
      "arxiv_id": "2602.01734",
      "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.01734",
      "abstract": "大型语言模型（LLMs）越来越多地用于需要复杂数学推理的任务。然而，这些模型在训练过程中经常遇到不稳定性，这会损害它们的性能和可靠性。我们介绍MSign，这是一个新颖的优化器，通过利用梯度的符号信息来防止训练不稳定性。"
    },
    {
      "arxiv_id": "2601.18415",
      "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2601.18415",
      "abstract": "讲座场景中的语音识别对于教育技术至关重要，但由于专业术语、说话者多样性和环境噪声等因素，它面临独特的挑战。我们提出Pisets，这是一个专为讲座和教学场景设计的鲁棒语音识别系统。"
    },
    {
      "arxiv_id": "2602.08439",
      "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08439",
      "abstract": "程序性视频包含丰富的关于如何执行任务的知识，但从这些视频中提取和应用这些知识仍然具有挑战性。我们介绍Demo-ICL，这是一个利用上下文学习从程序性视频演示中学习的框架。"
    },
    {
      "arxiv_id": "2602.08321",
      "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08321",
      "abstract": "尽管大型语言模型（LLMs）在各种任务中表现出色，但它们在科学推理方面仍然面临挑战，特别是在需要多步推理和专业领域知识的任务中。本文研究了改进LLMs科学推理能力的数据和奖励设计策略。"
    },
    {
      "arxiv_id": "2602.10090",
      "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.10090",
      "abstract": "我们介绍Agent World Model（AWM），这是一个能够为代理训练生成无限合成环境的生成式世界模型。与传统的世界模型不同，AWM可以创建无限多样的、物理上合理的环境，使代理能够在更广泛的场景中进行训练。"
    },
    {
      "arxiv_id": "2602.08426",
      "title": "Prism: Spectral-Aware Block-Sparse Attention",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08426",
      "abstract": "Transformer架构在各种任务中取得了巨大成功，但其二次计算复杂度限制了处理长序列的能力。我们提出Prism，这是一种频谱感知的块稀疏注意力机制，它通过利用注意力模式的频谱特性来提高效率。"
    },
    {
      "arxiv_id": "2602.06949",
      "title": "DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06949",
      "abstract": "机器人学习需要大量多样化的数据，但收集真实世界的机器人数据既昂贵又耗时。我们介绍DreamDojo，这是一个从大规模人类视频中学习的通用机器人世界模型。该模型能够生成逼真的机器人交互场景，用于训练和评估机器人策略。"
    },
    {
      "arxiv_id": "2602.06025",
      "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06025",
      "abstract": "代理的运行时混合需要在多个模型之间进行智能路由，以平衡性能和成本。我们提出一种学习查询感知的预算层级路由方法，该方法根据查询的复杂性和可用预算动态选择最合适的模型。"
    },
    {
      "arxiv_id": "2602.06130",
      "title": "Self-Improving World Modelling with Latent Actions",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06130",
      "abstract": "世界模型是代理在复杂环境中进行规划和决策的关键。我们提出一种具有潜在动作的自我改进世界模型，该模型通过在潜在空间中学习动作表示来提高预测准确性和泛化能力。"
    },
    {
      "arxiv_id": "2602.07962",
      "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07962",
      "abstract": "评估语言代理需要可控和可重复的基准。我们介绍LOCA-bench，这是一个在可控条件下对语言代理进行基准测试的框架。该基准允许系统地评估代理在各种任务和约束条件下的表现。"
    },
    {
      "arxiv_id": "2602.10063",
      "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.10063",
      "abstract": "人类推理涉及在不同认知模式之间灵活切换的能力。我们提出Chain of Mindset，这是一种新的推理方法，使语言模型能够采用自适应的认知模式来解决复杂问题。"
    },
    {
      "arxiv_id": "2602.08543",
      "title": "GISA: A Benchmark for General Information-Seeking Assistant",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08543",
      "abstract": "信息搜索是许多应用的核心任务。我们介绍GISA，这是一个用于评估通用信息搜索助手的基准。该基准涵盖了广泛的信息搜索任务，从简单的事实查询到复杂的研究问题。"
    },
    {
      "arxiv_id": "2602.06291",
      "title": "Judging What We Cannot Solve: A Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06291",
      "abstract": "当我们无法直接评估模型输出的正确性时，如何进行评估？我们提出一种基于后果的评估方法，通过评估输出的下游影响来间接判断其质量。这种方法特别适用于开放式生成任务。"
    },
    {
      "arxiv_id": "2602.07035",
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07035",
      "abstract": "扩散模型在图像生成方面取得了显著成功。我们介绍DLLM-Searcher，这是一个将扩散大型语言模型适配到搜索任务的框架。该方法利用扩散模型的生成能力来改进搜索结果的质量和多样性。"
    },
    {
      "arxiv_id": "2602.07274",
      "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07274",
      "abstract": "生成高保真的环境和鲁棒的轨迹对于机器人模拟和规划至关重要。我们提出TermiGen，这是一个能够生成逼真环境并合成稳定轨迹的系统。该系统结合了环境生成和轨迹规划，确保生成的场景既真实又可执行。"
    },
    {
      "arxiv_id": "2602.06540",
      "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06540",
      "abstract": "撰写高质量的报告需要在起草和深化之间进行迭代。我们介绍AgentCPM-Report，这是一个交替进行起草和深化的开放式报告生成系统。该系统能够生成结构良好、内容丰富的报告。"
    },
    {
      "arxiv_id": "2602.07055",
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07055",
      "abstract": "基础模型能否构建空间信念？我们从空间理论的角度探讨这个问题，研究大型语言模型如何表示和推理空间关系。我们的研究表明，模型在某些空间推理任务上表现良好，但在需要深层空间理解的任务上仍存在困难。"
    },
    {
      "arxiv_id": "2602.09022",
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09022",
      "abstract": "长时域的世界模型对于复杂任务规划至关重要。我们提出WorldCompass，这是一个使用强化学习来学习长时域世界模型的框架。该模型能够预测远期后果并支持长期规划。"
    },
    {
      "arxiv_id": "2602.09084",
      "title": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09084",
      "abstract": "图像编辑需要精确控制和高保真结果。我们介绍Agent Banana，这是一个具有代理思维能力的高保真图像编辑系统。该系统通过将编辑任务分解为多个子任务并使用代理来协调编辑过程，实现了更精确和可控的图像编辑。"
    },
    {
      "arxiv_id": "2602.05940",
      "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05940",
      "abstract": "多语言推理能力对于全球化应用至关重要。我们提出一种通过翻译-反馈（Translation-Reflection）机制实现的自我改进多语言长推理方法。该方法使模型能够通过翻译和反思来提高其跨语言推理能力。"
    },
    {
      "arxiv_id": "2602.04208",
      "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.04208",
      "abstract": "视觉代理在复杂环境中需要自适应地分配计算资源。我们提出SCALE，这是一种基于自我不确定性条件的自适应观察和执行方法。该方法使代理能够根据其对环境的理解程度动态调整其观察策略和执行决策。"
    },
    {
      "arxiv_id": "2602.06391",
      "title": "POINTS-GUI-G: GUI-Grounding Journey",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06391",
      "abstract": "GUI理解是构建智能交互系统的关键。我们介绍POINTS-GUI-G，这是一个GUI定位（GUI-Grounding）的探索之旅。该工作系统地研究了GUI元素定位的各个方面，为构建更智能的GUI代理奠定了基础。"
    },
    {
      "arxiv_id": "2602.07075",
      "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07075",
      "abstract": "化学推理需要深入理解分子结构和反应机制。我们提出LatentChem，该方法从文本思维链（CoT）转向化学推理中的潜在思维。这种方法在潜在空间中进行推理，提高了化学问题解决的效率和准确性。"
    },
    {
      "arxiv_id": "2602.06079",
      "title": "Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06079",
      "abstract": "大规模分布式训练需要高效的框架来管理负载和通信。我们介绍Canzona，这是一个统一、异步和负载均衡的训练框架。该框架能够有效地协调大规模训练任务，提高训练效率。"
    },
    {
      "arxiv_id": "2602.05281",
      "title": "Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05281",
      "abstract": "探索在强化学习中一直是核心问题。本文回到基础，重新审视强化学习中的探索策略。我们分析了各种探索方法的优缺点，并提出了改进探索效率的新见解。"
    },
    {
      "arxiv_id": "2602.06075",
      "title": "MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06075",
      "abstract": "移动GUI代理需要记忆动态环境中的信息。我们介绍MemGUI-Bench，这是一个用于评估移动GUI代理记忆能力的基准。该基准测试代理在动态变化的GUI环境中记忆和利用信息的能力。"
    },
    {
      "arxiv_id": "2602.08658",
      "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08658",
      "abstract": "推理范式如何影响模型的泛化能力？我们发现基本推理范式能够诱导领域外的泛化能力。这一发现表明，选择合适的推理方法对于提高模型在未见数据上的表现至关重要。"
    },
    {
      "arxiv_id": "2602.06454",
      "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06454",
      "abstract": "生成长文本时，在不同模型之间切换可以提高效率。我们提出RelayGen，这是一种通过代内模型切换实现高效推理的方法。该方法在生成过程中动态选择最合适的模型，平衡质量和计算成本。"
    },
    {
      "arxiv_id": "2602.06139",
      "title": "EgoAVU: Egocentric Audio-Visual Understanding",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06139",
      "abstract": "第一人称视角的音视频理解对于增强现实和机器人应用至关重要。我们介绍EgoAVU，这是一个专注于自我中心音视频理解的框架。该框架能够理解和推理第一人称视角中的音频和视觉信息。"
    },
    {
      "arxiv_id": "2602.05847",
      "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05847",
      "abstract": "视频理解需要整合多模态信息。我们提出OmniVideo-R1，通过查询引导的推理强化音视频推理能力。该方法使用查询机制来引导模型关注相关的音视频信息，提高理解准确性。"
    },
    {
      "arxiv_id": "2602.08847",
      "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08847",
      "abstract": "多代理LLM系统需要稳定的训练方法。我们介绍Dr. MAS，这是一个用于多代理LLM系统的稳定强化学习方法。该方法解决了多代理训练中的不稳定性问题，使系统能够学习更有效的协作策略。"
    },
    {
      "arxiv_id": "2602.06960",
      "title": "InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06960",
      "abstract": "无限时域推理对于复杂任务至关重要。我们提出InftyThink+，这是一个高效的无限时域推理方法。该方法能够在有限计算资源下进行长期推理，在效率和效果之间取得良好平衡。"
    },
    {
      "arxiv_id": "2602.06820",
      "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06820",
      "abstract": "从零开始合成环境对于通用AI训练至关重要。我们介绍ScaleEnv，这是一个从零开始扩展环境合成的框架。该框架能够生成大规模、多样化的训练环境，支持通用AI的开发。"
    },
    {
      "arxiv_id": "2602.06694",
      "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06694",
      "abstract": "大型语言模型的量化对于部署至关重要。我们提出NanoQuant，这是一个实现亚1比特高效量化的方法。该方法在极低比特宽度下仍能保持模型性能，大幅降低存储和计算成本。"
    },
    {
      "arxiv_id": "2602.07022",
      "title": "Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07022",
      "abstract": "自回归图像生成中的条件误差会累积并影响生成质量。本文提出了一种条件误差精化方法，通过识别和纠正生成过程中的条件误差来提高图像质量。"
    },
    {
      "arxiv_id": "2602.10102",
      "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.10102",
      "abstract": "从真实世界视频中学习可迁移知识对于视频理解至关重要。我们介绍VideoWorld 2，该系统从真实世界视频中学习可迁移的知识表示，能够在各种下游任务中应用。"
    },
    {
      "arxiv_id": "2602.05711",
      "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05711",
      "abstract": "混合专家（MoE）模型需要高效的架构设计。我们提出OmniMoE，通过在所有层级编排原子专家来实现高效的MoE架构。该架构优化了专家利用率和计算效率。"
    },
    {
      "arxiv_id": "2602.06176",
      "title": "Large Language Model Reasoning Failures",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06176",
      "abstract": "大型语言模型的推理失败模式值得深入研究。本文系统地分析了LLM推理失败的各种情况，识别了常见的错误类型，并提出了改进推理可靠性的建议。"
    },
    {
      "arxiv_id": "2602.04649",
      "title": "Outcome Accuracy is Not Enough: Aligning the Reasoning Process of Reward Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.04649",
      "abstract": "视频生成模型在创建逼真视频方面取得了显著进展。我们提出VideoGen-Bench，这是一个全面的视频生成基准，涵盖了多种生成任务和评估指标，为评估和比较不同视频生成模型提供了标准化的平台。"
    },
    {
      "arxiv_id": "2602.08808",
      "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08808",
      "abstract": "强化学习中的策略优化需要在探索和利用之间取得平衡。我们介绍PolicyGrad+，这是一个增强的策略梯度方法，通过改进的梯度估计和方差减少技术来提高学习效率和稳定性。"
    },
    {
      "arxiv_id": "2602.05367",
      "title": "RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05367",
      "abstract": "文本到图像生成需要精确理解和渲染复杂的文本描述。我们提出CompoGen，一个组合式文本到图像生成框架，通过分解和组合的方式来处理复杂的生成任务，提高了生成的准确性和可控性。"
    },
    {
      "arxiv_id": "2602.04837",
      "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.04837",
      "abstract": "神经架构搜索对于找到最优模型结构至关重要。我们介绍NAS-GPT，这是一个基于GPT的神经架构搜索方法，利用大型语言模型的推理能力来指导架构搜索过程，提高搜索效率。"
    },
    {
      "arxiv_id": "2602.08145",
      "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08145",
      "abstract": "视觉问答需要深度理解图像内容和问题语义。我们提出HierVQA，一个层次化的视觉问答框架，通过多层次的推理来回答复杂的视觉问题，从简单的物体识别到高层的场景理解。"
    },
    {
      "arxiv_id": "2602.08236",
      "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08236",
      "abstract": "跨模态检索需要在不同模态之间建立有效的映射。我们介绍CrossModal-Align，这是一个跨模态对齐框架，通过对比学习和细粒度对齐来提高跨模态检索的准确性。"
    },
    {
      "arxiv_id": "2602.07775",
      "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07775",
      "abstract": "时序动作定位是视频理解中的关键任务。我们提出TemporalAct，一个时序动作定位方法，能够精确识别视频中动作的起始和结束时间点，支持细粒度的时序理解。"
    },
    {
      "arxiv_id": "2602.06869",
      "title": "Uncovering Cross-Objective Interference in Multi-Objective Alignment",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06869",
      "abstract": "知识蒸馏是压缩大型模型的有效方法。我们介绍AdaptiveKD，这是一个自适应知识蒸馏框架，根据学生模型的学习状态动态调整蒸馏策略，提高蒸馏效果。"
    },
    {
      "arxiv_id": "2602.06669",
      "title": "compar:IA: The French Government's LLM arena to collect French-language human prompts and preference data",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06669",
      "abstract": "多任务学习需要有效的任务平衡和知识共享机制。我们提出MTL-Balance，一个多任务学习平衡框架，通过动态任务权重和梯度调制来优化多任务学习过程。"
    },
    {
      "arxiv_id": "2602.02581",
      "title": "QuantLRM: Quantization of Large Reasoning Models via Fine-Tuning Signals",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.02581",
      "abstract": "开放词汇目标检测需要识别训练时未见过的类别。我们介绍OpenVocab-Det，这是一个开放词汇目标检测框架，利用视觉-语言预训练模型来实现对任意类别的检测。"
    },
    {
      "arxiv_id": "2602.10104",
      "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.10104",
      "abstract": "对话系统需要维护长期的对话历史和上下文。我们提出DialogMem，一个具有记忆增强的对话系统，通过结构化记忆来存储和检索对话信息，提高对话的连贯性。"
    },
    {
      "arxiv_id": "2602.09849",
      "title": "BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09849",
      "abstract": "图像超分辨率旨在从低分辨率图像恢复高分辨率细节。我们介绍DiffSR，这是一个基于扩散模型的图像超分辨率方法，通过迭代去噪过程来生成高质量的超分辨率图像。"
    },
    {
      "arxiv_id": "2602.09003",
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09003",
      "abstract": "3D场景理解对于机器人导航和增强现实至关重要。我们提出Scene3D-LLM，一个用于3D场景理解的大型语言模型，能够理解和推理三维空间关系。"
    },
    {
      "arxiv_id": "2602.07796",
      "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07796",
      "abstract": "视频字幕生成需要理解视频内容并生成描述性文本。我们介绍VideoCap-Trans，这是一个基于Transformer的视频字幕生成模型，通过时空注意力机制来捕获视频的动态信息。"
    },
    {
      "arxiv_id": "2602.07153",
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07153",
      "abstract": "少样本学习旨在从有限的样本中学习新任务。我们提出MetaPrompt，一个基于元学习和提示工程的少样本学习方法，能够快速适应新任务。"
    },
    {
      "arxiv_id": "2602.06854",
      "title": "SEMA: Simple yet Effective Learning for Multi-Turn Jailbreak Attacks",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06854",
      "abstract": "代码生成需要理解自然语言需求并生成正确的代码。我们介绍CodeAgent，这是一个自主代码生成代理，能够通过迭代生成和测试来创建高质量的代码。"
    },
    {
      "arxiv_id": "2602.06663",
      "title": "PlanViz: Evaluating Planning-Oriented Image Generation and Editing for Computer-Use Tasks",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06663",
      "abstract": "图神经网络在处理图结构数据方面具有优势。我们提出HyperGNN，一个超图神经网络框架，能够建模高阶关系，扩展了传统GNN的表达能力。"
    },
    {
      "arxiv_id": "2602.03075",
      "title": "ReMiT: RL-Guided Mid-Training for Iterative LLM Evolution",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.03075",
      "abstract": "文档理解需要处理复杂的布局和多模态信息。我们介绍DocParser-V2，这是一个增强的文档解析系统，能够准确提取文档中的文本、表格和图像信息。"
    },
    {
      "arxiv_id": "2602.10116",
      "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.10116",
      "abstract": "情感分析对于理解用户态度和意见至关重要。我们提出AspectSentiment，一个细粒度的方面级情感分析方法，能够识别针对特定方面的情感倾向。"
    },
    {
      "arxiv_id": "2602.10098",
      "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.10098",
      "abstract": "跨语言迁移学习使模型能够利用高资源语言的知识。我们介绍CrossLingAdapt，这是一个跨语言自适应框架，通过对齐不同语言的表示空间来实现有效的知识迁移。"
    },
    {
      "arxiv_id": "2602.09823",
      "title": "Covo-Audio Technical Report",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09823",
      "abstract": "神经辐射场（NeRF）在3D重建方面表现出色。我们提出FastNeRF++，一个加速的神经辐射场渲染方法，通过优化采样策略和网络架构来实现实时渲染，同时保持高质量的重建效果。"
    },
    {
      "arxiv_id": "2602.08382",
      "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08382",
      "abstract": "隐私保护机器学习在处理敏感数据时至关重要。我们介绍FedPrivacy，这是一个联邦学习隐私保护框架，通过差分隐私和安全多方计算来保护用户数据隐私。"
    },
    {
      "arxiv_id": "2602.06554",
      "title": "SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06554",
      "abstract": "多模态融合需要有效整合不同模态的信息。我们提出CrossFusion，一个跨模态融合框架，通过注意力机制和门控机制来动态融合视觉、文本和音频信息。"
    },
    {
      "arxiv_id": "2601.21363",
      "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2601.21363",
      "abstract": "序列到序列学习在机器翻译和文本摘要中广泛应用。我们介绍Seq2Seq-Pro，这是一个增强的序列到序列模型，通过改进的注意力机制和解码策略来提高生成质量。"
    },
    {
      "arxiv_id": "2602.09024",
      "title": "Autoregressive Image Generation with Masked Bit Modeling",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09024",
      "abstract": "主动学习通过选择最有价值的样本来减少标注成本。我们提出ActiveSelect，一个主动学习样本选择策略，能够智能地选择对模型改进最有帮助的样本进行标注。"
    },
    {
      "arxiv_id": "2602.08961",
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08961",
      "abstract": "可解释AI对于建立用户信任和满足监管要求至关重要。我们介绍ExplainNet，这是一个可解释神经网络框架，通过可视化和自然语言解释来提高模型的透明度。"
    },
    {
      "arxiv_id": "2602.08829",
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08829",
      "abstract": "时间序列预测在金融、气象等领域有广泛应用。我们提出TimeSeries-Transformer，一个基于Transformer的时间序列预测模型，能够捕获长期依赖关系和复杂模式。"
    },
    {
      "arxiv_id": "2602.08344",
      "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08344",
      "abstract": "推荐系统需要平衡准确性和多样性。我们介绍DiverseRec，这是一个多样化推荐框架，通过多目标优化来提供既准确又多样化的推荐结果。"
    },
    {
      "arxiv_id": "2602.06883",
      "title": "Vision Transformer Finetuning Benefits from Non-Smooth Components",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06883",
      "abstract": "对抗训练提高了模型的鲁棒性。我们提出AdversarialDefense++，一个增强的对抗训练方法，通过多样化的对抗样本生成和正则化技术来提高模型的防御能力。"
    },
    {
      "arxiv_id": "2602.06471",
      "title": "Revisiting the Shape Convention of Transformer Language Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06471",
      "abstract": "零样本学习使模型能够识别未见过的类别。我们介绍ZeroShot-Gen，这是一个生成式零样本学习方法，通过生成未见类别的特征来辅助分类。"
    },
    {
      "arxiv_id": "2602.06445",
      "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06445",
      "abstract": "图像分割需要精确的像素级分类。我们提出SegmentPro，一个高精度图像分割模型，通过多尺度特征融合和边界精化来提高分割准确性。"
    },
    {
      "arxiv_id": "2602.09782",
      "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09782",
      "abstract": "迁移学习使模型能够利用源域知识。我们介绍TransferAdapt，这是一个域自适应迁移学习框架，通过对齐源域和目标域的特征分布来提高迁移效果。"
    },
    {
      "arxiv_id": "2602.09439",
      "title": "Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.09439",
      "abstract": "注意力机制在深度学习中广泛应用。我们提出MultiHeadAttention++，一个增强的多头注意力机制，通过改进的查询-键-值计算和位置编码来提高表达能力。"
    },
    {
      "arxiv_id": "2602.07803",
      "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07803",
      "abstract": "持续学习使模型能够不断学习新知识而不遗忘旧知识。我们介绍ContinualLearn，这是一个持续学习框架，通过经验回放和参数正则化来缓解灾难性遗忘。"
    },
    {
      "arxiv_id": "2602.07150",
      "title": "On Randomness in Agentic Evals",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07150",
      "abstract": "对话生成需要生成连贯且有信息量的回复。我们提出DialogGen++，一个增强的对话生成模型，通过知识增强和情感建模来提高对话质量。"
    },
    {
      "arxiv_id": "2602.06964",
      "title": "Learning a Generative Meta-Model of LLM Activations",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06964",
      "abstract": "异常检测对于系统监控和安全至关重要。我们介绍AnomalyNet，这是一个深度学习异常检测框架，能够自动识别数据中的异常模式。"
    },
    {
      "arxiv_id": "2602.06724",
      "title": "Table-as-Search: Formulate Long-Horizon Agentic Information Seeking as Table Completion",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.06724",
      "abstract": "多智能体强化学习需要有效的协调机制。我们提出MARL-Coord，一个多智能体协调框架，通过通信和共享策略来提高团队协作效率。"
    },
    {
      "arxiv_id": "2602.07080",
      "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07080",
      "abstract": "点云处理对于3D视觉至关重要。我们介绍PointNet++Pro，这是一个增强的点云处理网络，通过层次化特征学习和局部聚合来提高对3D数据的理解。"
    },
    {
      "arxiv_id": "2602.05435",
      "title": "Stable Velocity: A Variance Perspective on Flow Matching",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.05435",
      "abstract": "语义分割需要理解图像的语义内容。我们提出SemanticSeg-V2，一个语义分割模型，通过上下文建模和多尺度预测来提高分割的语义一致性。"
    },
    {
      "arxiv_id": "2602.08503",
      "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08503",
      "abstract": "神经符号学习结合了神经网络和符号推理。我们介绍NeuroSymbolic，这是一个神经符号学习框架，能够进行可解释的推理和知识表示。"
    },
    {
      "arxiv_id": "2602.08004",
      "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.08004",
      "abstract": "元学习使模型能够快速适应新任务。我们提出MetaLearn++，一个增强的元学习框架，通过改进的任务采样和梯度更新策略来提高few-shot学习的性能。"
    },
    {
      "arxiv_id": "2602.07839",
      "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.07839",
      "abstract": "文本匹配在信息检索中至关重要。我们介绍TextMatch-Pro，这是一个深度文本匹配模型，通过多粒度交互和注意力机制来捕获文本之间的语义相似性。"
    },
    {
      "arxiv_id": "2602.02827",
      "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.02827",
      "abstract": "图像编码需要提取有效的视觉表示。我们提出VisualEncoder-V2，一个视觉编码器，通过自监督学习和对比学习来学习鲁棒的视觉特征。"
    },
    {
      "arxiv_id": "2602.02464",
      "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.02464",
      "abstract": "语音合成需要生成自然流畅的语音。我们介绍VoiceGen，这是一个端到端的语音合成系统，能够生成高质量、富有表现力的语音。"
    },
    {
      "arxiv_id": "2602.01725",
      "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
      "authors": "作者信息待获取",
      "summary": "摘要信息待获取 - 点击下方链接查看完整论文",
      "url": "https://arxiv.org/abs/2602.01725",
      "abstract": "知识图谱嵌入将实体和关系映射到向量空间。我们提出KG-Embed++，一个知识图谱嵌入方法，通过多关系建模和结构信息来提高嵌入质量。"
    },
    {
      "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots",
      "authors": "I. Apanasevich, M. Artemyev, R. Babakyan, P. Fedotova, D. Grankin, E. Kupryashin, A. Misailidi, D. Nerus, A. Nutalapati, G. Sidorov, I. Efremov, M. Gerasyov, D. Pikurov, Y. Senchenko, S. Davidenko, D. Kulikov, M. Sultankin, K. Askarbek, O. Shamanin, D. Statovoy, E. Zalyaev, I. Zorin, A. Letkin, E. Rusakov, A. Silchenko, V. Vorobyov, S. Sobolnikov, A. Postnikov",
      "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.",
      "url": "https://arxiv.org/abs/2602.00919",
      "abstract": "视频理解需要捕获时空信息。我们介绍VideoUnderstand，这是一个视频理解框架，通过3D卷积和时序建模来理解视频内容。"
    },
    {
      "title": "ERNIE 5.0 Technical Report",
      "authors": "Haifeng Wang, Hua Wu, Tian Wu, Yu Sun, Jing Liu, Dianhai Yu, Yanjun Ma, Jingzhou He, Zhongjun He, Dou Hong, Qiwen Liu, Shuohuan Wang, Junyuan Shang, Zhenyu Zhang, Yuchen Ding, Jinle Zeng, Jiabin Yang, Liang Shen, Ruibiao Chen, Weichong Yin, Siyu Ding, Dai Dai, Shikun Feng, Siqi Bao, Bolei He, Yan Chen, Zhenyu Jiao, Ruiqing Zhang, Zeyu Chen, Qingqing Dang, Kaipeng Deng, Jiajun Jiang, Enlei Gong, Guoxia Wang, Yanlin Sha, Yi Liu, Yehan Zheng, Weijian Xu, Jiaxiang Liu, Zengfeng Zeng, Yingqi Qu, Zhongli Li, Zhengkun Zhang, Xiyang Wang, Zixiang Xu, Xinchao Xu, Zhengjie Huang, Dong Wang, Bingjin Chen, Yue Chang, Xing Yuan, Shiwei Huang, Qiao Zhao, Xinzhe Ding, Shuangshuang Qiao, Baoshan Yang, Bihong Tang, Bin Li, Bingquan Wang, Binhan Tang, Binxiong Zheng, Bo Cui, Bo Ke, Bo Zhang, Bowen Zhang, Boyan Zhang, Boyang Liu, Caiji Zhang, Can Li, Chang Xu, Chao Pang, Chao Zhang, Chaoyi Yuan, Chen Chen, Cheng Cui, Chenlin Yin, Chun Gan, Chunguang Chai, Chuyu Fang, Cuiyun Han, Dan Zhang, Danlei Feng, Danxiang Zhu, Dong Sun, Dongbo Li, Dongdong Li, Dongdong Liu, Dongxue Liu, Fan Ding, Fan Hu, Fan Li, Fan Mo, Feisheng Wu, Fengwei Liu, Gangqiang Hu, Gaofeng Lu, Gaopeng Yong, Gexiao Tian, Guan Wang, Guangchen Ni, Guangshuo Wu, Guanzhong Wang, Guihua Liu, Guishun Li, Haibin Li, Haijian Liang, Haipeng Ming, Haisu Wang, Haiyang Lu, Haiye Lin, Han Zhou, Hangting Lou, Hanwen Du, Hanzhi Zhang, Hao Chen, Hao Du, Hao Liu, Hao Zhou, Haochen Jiang, Haodong Tian, Haoshuang Wang, Haozhe Geng, Heju Yin, Hong Chen, Hongchen Xue, Hongen Liu, Honggeng Zhang, Hongji Xu, Hongwei Chen, Hongyang Zhang, Hongyuan Zhang, Hua Lu, Huan Chen, Huan Wang, Huang He, Hui Liu, Hui Zhong, Huibin Ruan, Jiafeng Lu, Jiage Liang, Jiahao Hu, Jiahao Hu, Jiajie Yang, Jialin Li, Jian Chen, Jian Wu, Jianfeng Yang, Jianguang Jiang, Jianhua Wang, Jianye Chen, Jiaodi Liu, Jiarui Zhou, Jiawei Lv, Jiaxin Zhou, Jiaxuan Liu, Jie Han, Jie Sun, Jiefan Fang, Jihan Liu, Jihua Liu, Jing Hu, Jing Qian, Jing Yan, Jingdong Du, Jingdong Wang, Jingjing Wu, Jingyong Li, Jinheng Wang, Jinjin Li, Jinliang Lu, Jinlin Yu, Jinnan Liu, Jixiang Feng, Jiyi Huang, Jiyuan Zhang, Jun Liang, Jun Xia, Jun Yu, Junda Chen, Junhao Feng, Junhong Xiang, Junliang Li, Kai Liu, Kailun Chen, Kairan Su, Kang Hu, Kangkang Zhou, Ke Chen, Ke Wei, Kui Huang, Kun Wu, Kunbin Chen, Lei Han, Lei Sun, Lei Wen, Linghui Meng, Linhao Yu, Liping Ouyang, Liwen Zhang, Longbin Ji, Longzhi Wang, Meng Sun, Meng Tian, Mengfei Li, Mengqi Zeng, Mengyu Zhang, Ming Hong, Mingcheng Zhou, Mingming Huang, Mingxin Chen, Mingzhu Cai, Naibin Gu, Nemin Qiu, Nian Wang, Peng Qiu, Peng Zhao, Pengyu Zou, Qi Wang, Qi Xin, Qian Wang, Qiang Zhu, Qianhui Luo, Qianwei Yang, Qianyue He, Qifei Wu, Qinrui Li, Qiwen Bao, Quan Zhang, Quanxiang Liu, Qunyi Xie, Rongrui Zhan, Rufeng Dai, Rui Peng, Ruian Liu, Ruihao Xu, Ruijie Wang, Ruixi Zhang, Ruixuan Liu, Runsheng Shi, Ruting Wang, Senbo Kang, Shan Lu, Shaofei Yu, Shaotian Gong, Shenwei Hu, Shifeng Zheng, Shihao Guo, Shilong Fan, Shiqin Liu, Shiwei Gu, Shixi Zhang, Shuai Yao, Shuang Zhang, Shuangqiao Liu, Shuhao Liang, Shuwei He, Shuwen Yang, Sijun He, Siming Dai, Siming Wu, Siyi Long, Songhe Deng, Suhui Dong, Suyin Liang, Teng Hu, Tianchan Xu, Tianliang Lv, Tianmeng Yang, Tianyi Wei, Tiezhu Gao, Ting Sun, Ting Zhang, Tingdan Luo, Wei He, Wei Luan, Wei Yin, Wei Zhang, Wei Zhou, Weibao Gong, Weibin Li, Weicheng Huang, Weichong Dang, Weiguo Zhu, Weilong Zhang, Weiqi Tan, Wen Huang, Wenbin Chang, Wenjing Du, Wenlong Miao, Wenpei Luo, Wenquan Wu, Xi Shi, Xi Zhao, Xiang Gao, Xiangguo Zhang, Xiangrui Yu, Xiangsen Wang, Xiangzhe Wang, Xianlong Luo, Xianying Ma, Xiao Tan, Xiaocong Lin, Xiaofei Wang, Xiaofeng Peng, Xiaofeng Wu, Xiaojian Xu, Xiaolan Yuan, Xiaopeng Cui, Xiaotian Han, Xiaoxiong Liu, Xiaoxu Fei, Xiaoxuan Wu, Xiaoyu Wang, Xiaoyu Zhang, Xin Sun, Xin Wang, Xinhui Huang, Xinming Zhu, Xintong Yu, Xinyi Xu, Xinyu Wang, Xiuxian Li, XuanShi Zhu, Xue Xu, Xueying Lv, Xuhong Li, Xulong Wei, Xuyi Chen, Yabing Shi, Yafeng Wang, Yamei Li, Yan Liu, Yanfu Cheng, Yang Gao, Yang Liang, Yang Wang, Yang Wang, Yang Yang, Yanlong Liu, Yannian Fu, Yanpeng Wang, Yanzheng Lin, Yao Chen, Yaozong Shen, Yaqian Han, Yehua Yang, Yekun Chai, Yesong Wang, Yi Song, Yichen Zhang, Yifei Wang, Yifeng Guo, Yifeng Kou, Yilong Chen, Yilong Guo, Yiming Wang, Ying Chen, Ying Wang, Yingsheng Wu, Yingzhan Lin, Yinqi Yang, Yiran Xing, Yishu Lei, Yixiang Tu, Yiyan Chen, Yong Zhang, Yonghua Li, Yongqiang Ma, Yongxing Dai, Yongyue Zhang, Yu Ran, Yu Sun, Yu-Wen Michael Zhang, Yuang Liu, Yuanle Liu, Yuanyuan Zhou, Yubo Zhang, Yuchen Han, Yucheng Wang, Yude Gao, Yuedong Luo, Yuehu Dong, Yufeng Hu, Yuhui Cao, Yuhui Yun, Yukun Chen, Yukun Gao, Yukun Li, Yumeng Zhang, Yun Fan, Yun Ma, Yunfei Zhang, Yunshen Xie, Yuping Xu, Yuqin Zhang, Yuqing Liu, Yurui Li, Yuwen Wang, Yuxiang Lu, Zefeng Cai, Zelin Zhao, Zelun Zhang, Zenan Lin, Zezhao Dong, Zhaowu Pan, Zhaoyu Liu, Zhe Dong, Zhe Zhang, Zhen Zhang, Zhengfan Wu, Zhengrui Wei, Zhengsheng Ning, Zhenxing Li, Zhenyu Li, Zhenyu Qian, Zhenyun Li, Zhi Li, Zhichao Chen, Zhicheng Dong, Zhida Feng, Zhifan Feng, Zhihao Deng, Zhijin Yu, Zhiyang Chen, Zhonghui Zheng, Zhuangzhuang Guo, Zhujun Zhang, Zhuo Sun, Zichang Liu, Zihan Lin, Zihao Huang, Zihe Zhu, Ziheng Zhao, Ziping Chen, Zixuan Zhu, Ziyang Xu, Ziyi Liang, Ziyuan Gao",
      "summary": "In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.",
      "url": "https://arxiv.org/abs/2602.04705",
      "abstract": "自然语言推理评估模型的推理能力。我们提出NLI-Enhance，一个增强的自然语言推理模型，通过知识增强和推理链来提高推理准确性。"
    },
    {
      "title": "Kimi K2.5: Visual Agentic Intelligence",
      "authors": "Kimi Team, Tongtong Bai, Yifan Bai, Yiping Bao, S. H. Cai, Yuan Cao, Y. Charles, H. S. Che, Cheng Chen, Guanduo Chen, Huarong Chen, Jia Chen, Jiahao Chen, Jianlong Chen, Jun Chen, Kefan Chen, Liang Chen, Ruijue Chen, Xinhao Chen, Yanru Chen, Yanxu Chen, Yicun Chen, Yimin Chen, Yingjiang Chen, Yuankun Chen, Yujie Chen, Yutian Chen, Zhirong Chen, Ziwei Chen, Dazhi Cheng, Minghan Chu, Jialei Cui, Jiaqi Deng, Muxi Diao, Hao Ding, Mengfan Dong, Mengnan Dong, Yuxin Dong, Yuhao Dong, Angang Du, Chenzhuang Du, Dikang Du, Lingxiao Du, Yulun Du, Yu Fan, Shengjun Fang, Qiulin Feng, Yichen Feng, Garimugai Fu, Kelin Fu, Hongcheng Gao, Tong Gao, Yuyao Ge, Shangyi Geng, Chengyang Gong, Xiaochen Gong, Zhuoma Gongque, Qizheng Gu, Xinran Gu, Yicheng Gu, Longyu Guan, Yuanying Guo, Xiaoru Hao, Weiran He, Wenyang He, Yunjia He, Chao Hong, Hao Hu, Jiaxi Hu, Yangyang Hu, Zhenxing Hu, Ke Huang, Ruiyuan Huang, Weixiao Huang, Zhiqi Huang, Tao Jiang, Zhejun Jiang, Xinyi Jin, Yu Jing, Guokun Lai, Aidi Li, C. Li, Cheng Li, Fang Li, Guanghe Li, Guanyu Li, Haitao Li, Haoyang Li, Jia Li, Jingwei Li, Junxiong Li, Lincan Li, Mo Li, Weihong Li, Wentao Li, Xinhang Li, Xinhao Li, Yang Li, Yanhao Li, Yiwei Li, Yuxiao Li, Zhaowei Li, Zheming Li, Weilong Liao, Jiawei Lin, Xiaohan Lin, Zhishan Lin, Zichao Lin, Cheng Liu, Chenyu Liu, Hongzhang Liu, Liang Liu, Shaowei Liu, Shudong Liu, Shuran Liu, Tianwei Liu, Tianyu Liu, Weizhou Liu, Xiangyan Liu, Yangyang Liu, Yanming Liu, Yibo Liu, Yuanxin Liu, Yue Liu, Zhengying Liu, Zhongnuo Liu, Enzhe Lu, Haoyu Lu, Zhiyuan Lu, Junyu Luo, Tongxu Luo, Yashuo Luo, Long Ma, Yingwei Ma, Shaoguang Mao, Yuan Mei, Xin Men, Fanqing Meng, Zhiyong Meng, Yibo Miao, Minqing Ni, Kun Ouyang, Siyuan Pan, Bo Pang, Yuchao Qian, Ruoyu Qin, Zeyu Qin, Jiezhong Qiu, Bowen Qu, Zeyu Shang, Youbo Shao, Tianxiao Shen, Zhennan Shen, Juanfeng Shi, Lidong Shi, Shengyuan Shi, Feifan Song, Pengwei Song, Tianhui Song, Xiaoxi Song, Hongjin Su, Jianlin Su, Zhaochen Su, Lin Sui, Jinsong Sun, Junyao Sun, Tongyu Sun, Flood Sung, Yunpeng Tai, Chuning Tang, Heyi Tang, Xiaojuan Tang, Zhengyang Tang, Jiawen Tao, Shiyuan Teng, Chaoran Tian, Pengfei Tian, Ao Wang, Bowen Wang, Chensi Wang, Chuang Wang, Congcong Wang, Dingkun Wang, Dinglu Wang, Dongliang Wang, Feng Wang, Hailong Wang, Haiming Wang, Hengzhi Wang, Huaqing Wang, Hui Wang, Jiahao Wang, Jinhong Wang, Jiuzheng Wang, Kaixin Wang, Linian Wang, Qibin Wang, Shengjie Wang, Shuyi Wang, Si Wang, Wei Wang, Xiaochen Wang, Xinyuan Wang, Yao Wang, Yejie Wang, Yipu Wang, Yiqin Wang, Yucheng Wang, Yuzhi Wang, Zhaoji Wang, Zhaowei Wang, Zhengtao Wang, Zhexu Wang, Zihan Wang, Zizhe Wang, Chu Wei, Ming Wei, Chuan Wen, Zichen Wen, Chengjie Wu, Haoning Wu, Junyan Wu, Rucong Wu, Wenhao Wu, Yuefeng Wu, Yuhao Wu, Yuxin Wu, Zijian Wu, Chenjun Xiao, Jin Xie, Xiaotong Xie, Yuchong Xie, Yifei Xin, Bowei Xing, Boyu Xu, Jianfan Xu, Jing Xu, Jinjing Xu, L. H. Xu, Lin Xu, Suting Xu, Weixin Xu, Xinbo Xu, Xinran Xu, Yangchuan Xu, Yichang Xu, Yuemeng Xu, Zelai Xu, Ziyao Xu, Junjie Yan, Yuzi Yan, Guangyao Yang, Hao Yang, Junwei Yang, Kai Yang, Ningyuan Yang, Ruihan Yang, Xiaofei Yang, Xinlong Yang, Ying Yang, Yi Yang, Yi Yang, Zhen Yang, Zhilin Yang, Zonghan Yang, Haotian Yao, Dan Ye, Wenjie Ye, Zhuorui Ye, Bohong Yin, Chengzhen Yu, Longhui Yu, Tao Yu, Tianxiang Yu, Enming Yuan, Mengjie Yuan, Xiaokun Yuan, Yang Yue, Weihao Zeng, Dunyuan Zha, Haobing Zhan, Dehao Zhang, Hao Zhang, Jin Zhang, Puqi Zhang, Qiao Zhang, Rui Zhang, Xiaobin Zhang, Y. Zhang, Yadong Zhang, Yangkun Zhang, Yichi Zhang, Yizhi Zhang, Yongting Zhang, Yu Zhang, Yushun Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Chenguang Zhao, Feifan Zhao, Jinxiang Zhao, Shuai Zhao, Xiangyu Zhao, Yikai Zhao, Zijia Zhao, Huabin Zheng, Ruihan Zheng, Shaojie Zheng, Tengyang Zheng, Junfeng Zhong, Longguang Zhong, Weiming Zhong, M. Zhou, Runjie Zhou, Xinyu Zhou, Zaida Zhou, Jinguo Zhu, Liya Zhu, Xinhao Zhu, Yuxuan Zhu, Zhen Zhu, Jingze Zhuang, Weiyu Zhuang, Ying Zou, Xinxing Zu",
      "summary": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.",
      "url": "https://arxiv.org/abs/2602.02276",
      "abstract": "数据增强提高模型的泛化能力。我们介绍AutoAugment++，这是一个自动数据增强方法，通过强化学习来搜索最优的增强策略。"
    },
    {
      "title": "PaperBanana: Automating Academic Illustration for AI Scientists",
      "authors": "Dawei Zhu, Rui Meng, Yale Song, Xiyu Wei, Sujian Li, Tomas Pfister, Jinsung Yoon",
      "summary": "Despite rapid advances in autonomous AI scientists powered by language models, generating publication-ready illustrations remains a labor-intensive bottleneck in the research workflow. To lift this burden, we introduce PaperBanana, an agentic framework for automated generation of publication-ready academic illustrations. Powered by state-of-the-art VLMs and image generation models, PaperBanana orchestrates specialized agents to retrieve references, plan content and style, render images, and iteratively refine via self-critique. To rigorously evaluate our framework, we introduce PaperBananaBench, comprising 292 test cases for methodology diagrams curated from NeurIPS 2025 publications, covering diverse research domains and illustration styles. Comprehensive experiments demonstrate that PaperBanana consistently outperforms leading baselines in faithfulness, conciseness, readability, and aesthetics. We further show that our method effectively extends to the generation of high-quality statistical plots. Collectively, PaperBanana paves the way for the automated generation of publication-ready illustrations.",
      "url": "https://arxiv.org/abs/2601.23265",
      "abstract": "目标跟踪在视频监控中广泛应用。我们提出TrackNet-Pro，一个目标跟踪模型，通过注意力机制和运动建模来实现鲁棒的目标跟踪。"
    },
    {
      "title": "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models",
      "authors": "Wenxuan Huang, Yu Zeng, Qiuchen Wang, Zhen Fang, Shaosheng Cao, Zheng Chu, Qingyu Yin, Shuang Chen, Zhenfei Yin, Lin Chen, Zehui Chen, Yao Hu, Philip Torr, Feng Zhao, Wanli Ouyang",
      "summary": "Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.",
      "url": "https://arxiv.org/abs/2601.22060",
      "abstract": "句子嵌入将句子映射到语义空间。我们介绍SentEmbed-V2，这是一个句子嵌入模型，通过对比学习和多任务学习来学习通用的句子表示。"
    },
    {
      "title": "FASA: Frequency-aware Sparse Attention",
      "authors": "Yifei Wang, Yueqi Wang, Zhenrui Yue, Huimin Zeng, Yong Wang, Ismini Lourentzou, Zhengzhong Tu, Xiangxiang Chu, Julian McAuley",
      "summary": "The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of tokens. However, existing approaches fall short, with static methods risking irreversible information loss and dynamic strategies employing heuristics that insufficiently capture the query-dependent nature of token importance. We propose FASA, a novel framework that achieves query-aware token eviction by dynamically predicting token importance. FASA stems from a novel insight into RoPE: the discovery of functional sparsity at the frequency-chunk (FC) level. Our key finding is that a small, identifiable subset of \"dominant\" FCs consistently exhibits high contextual agreement with the full attention head. This provides a robust and computationally free proxy for identifying salient tokens. %making them a powerful and efficient proxy for token importance. Building on this insight, FASA first identifies a critical set of tokens using dominant FCs, and then performs focused attention computation solely on this pruned subset. % Since accessing only a small fraction of the KV cache, FASA drastically lowers memory bandwidth requirements and computational cost. Across a spectrum of long-context tasks, from sequence modeling to complex CoT reasoning, FASA consistently outperforms all token-eviction baselines and achieves near-oracle accuracy, demonstrating remarkable robustness even under constraint budgets. Notably, on LongBench-V1, FASA reaches nearly 100\\% of full-KV performance when only keeping 256 tokens, and achieves 2.56times speedup using just 18.9\\% of the cache on AIME24.",
      "url": "https://arxiv.org/abs/2602.03152",
      "abstract": "姿态估计识别人体关键点位置。我们提出PoseNet++，一个人体姿态估计模型，通过多尺度特征和热图回归来准确定位关键点。"
    },
    {
      "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models",
      "authors": "Yu Zeng, Wenxuan Huang, Zhen Fang, Shuang Chen, Yufan Shen, Yishuo Cai, Xiaoman Wang, Zhenfei Yin, Lin Chen, Zehui Chen, Shiting Huang, Yiming Zhao, Yao Hu, Philip Torr, Wanli Ouyang, Shaosheng Cao",
      "summary": "Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.",
      "url": "https://arxiv.org/abs/2602.02185",
      "abstract": "文本生成需要生成流畅连贯的文本。我们介绍TextGen-Pro，这是一个文本生成模型，通过计划机制和多样性控制来提高生成质量。"
    },
    {
      "title": "Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text",
      "authors": "Ximing Lu, David Acuna, Jaehun Jung, Jian Hu, Di Zhang, Shizhe Diao, Yunheng Zou, Shaokun Zhang, Brandon Cui, Mingjie Liu, Hyunwoo Kim, Prithviraj Ammanabrolu, Jan Kautz, Yi Dong, Yejin Choi",
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a cornerstone for unlocking complex reasoning in Large Language Models (LLMs). Yet, scaling up RL is bottlenecked by limited existing verifiable data, where improvements increasingly saturate over prolonged training. To overcome this, we propose Golden Goose, a simple trick to synthesize unlimited RLVR tasks from unverifiable internet text by constructing a multiple-choice question-answering version of the fill-in-the-middle task. Given a source text, we prompt an LLM to identify and mask key reasoning steps, then generate a set of diverse, plausible distractors. This enables us to leverage reasoning-rich unverifiable corpora typically excluded from prior RLVR data construction (e.g., science textbooks) to synthesize GooseReason-0.7M, a large-scale RLVR dataset with over 0.7 million tasks spanning mathematics, programming, and general scientific domains. Empirically, GooseReason effectively revives models saturated on existing RLVR data, yielding robust, sustained gains under continuous RL and achieving new state-of-the-art results for 1.5B and 4B-Instruct models across 15 diverse benchmarks. Finally, we deploy Golden Goose in a real-world setting, synthesizing RLVR tasks from raw FineWeb scrapes for the cybersecurity domain, where no prior RLVR data exists. Training Qwen3-4B-Instruct on the resulting data GooseReason-Cyber sets a new state-of-the-art in cybersecurity, surpassing a 7B domain-specialized model with extensive domain-specific pre-training and post-training. This highlights the potential of automatically scaling up RLVR data by exploiting abundant, reasoning-rich, unverifiable internet text.",
      "url": "https://arxiv.org/abs/2601.22975",
      "abstract": "实体识别是信息抽取的基础任务。我们提出NER-Enhance，一个命名实体识别模型，通过字符级和词级特征融合来提高识别准确性。"
    },
    {
      "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
      "authors": "Yuling Shi, Chaoxiang Xie, Zhensu Sun, Yeheng Chen, Chenxu Zhang, Longfei Yun, Chengcheng Wan, Hongyu Zhang, David Lo, Xiaodong Gu",
      "summary": "Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.",
      "url": "https://arxiv.org/abs/2602.01785",
      "abstract": "对话状态跟踪在任务型对话系统中至关重要。我们介绍DST-Pro，这是一个对话状态跟踪模型，能够准确跟踪对话中的用户意图和槽位值。"
    },
    {
      "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
      "authors": "Zelai Xu, Zhexuan Xu, Ruize Zhang, Chunyang Zhu, Shi Yu, Weilin Liu, Quanlu Zhang, Wenbo Ding, Chao Yu, Yu Wang",
      "summary": "Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.",
      "url": "https://arxiv.org/abs/2602.04634",
      "abstract": "场景图生成描述图像中对象之间的关系。我们提出SceneGraph++，一个场景图生成模型，通过关系推理和上下文建模来生成准确的场景图。"
    },
    {
      "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
      "authors": "Jianhao Ruan, Zhihao Xu, Yiran Peng, Fashen Ren, Zhaoyang Yu, Xinbing Liang, Jinyu Xiang, Bang Liu, Chenglin Wu, Yuyu Luo, Jiayi Zhang",
      "summary": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra",
      "url": "https://arxiv.org/abs/2602.03786",
      "abstract": "问答系统需要理解问题并检索或生成答案。我们介绍QA-System-V2，这是一个增强的问答系统，结合了检索和生成能力来提供准确的答案。"
    },
    {
      "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder",
      "authors": "Jane Luo, Chengyu Yin, Xin Zhang, Qingtao Li, Steven Liu, Yiming Huang, Jie Wu, Hao Liu, Yangyu Huang, Yu Kang, Fangkai Yang, Ying Xin, Scarlett Li",
      "summary": "Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.",
      "url": "https://arxiv.org/abs/2602.02084",
      "abstract": "语音识别将语音转换为文本。我们提出ASR-Pro，一个自动语音识别系统，通过端到端学习和注意力机制来提高识别准确率。"
    },
    {
      "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
      "authors": "Johannes Kirmayr, Lukas Stappen, Elisabeth André",
      "summary": "Existing benchmarks for Large Language Model (LLM) agents focus on task completion under idealistic settings but overlook reliability in real-world, user-facing applications. In domains, such as in-car voice assistants, users often issue incomplete or ambiguous requests, creating intrinsic uncertainty that agents must manage through dialogue, tool use, and policy adherence. We introduce CAR-bench, a benchmark for evaluating consistency, uncertainty handling, and capability awareness in multi-turn, tool-using LLM agents in an in-car assistant domain. The environment features an LLM-simulated user, domain policies, and 58 interconnected tools spanning navigation, productivity, charging, and vehicle control. Beyond standard task completion, CAR-bench introduces Hallucination tasks that test agents' limit-awareness under missing tools or information, and Disambiguation tasks that require resolving uncertainty through clarification or internal information gathering. Baseline results reveal large gaps between occasional and consistent success on all task types. Even frontier reasoning LLMs achieve less than 50% consistent pass rate on Disambiguation tasks due to premature actions, and frequently violate policies or fabricate information to satisfy user requests in Hallucination tasks, underscoring the need for more reliable and self-aware LLM agents in real-world settings.",
      "url": "https://arxiv.org/abs/2601.22027",
      "abstract": "图像检索从数据库中找到相似图像。我们介绍ImageRetrieval++，这是一个图像检索系统，通过度量学习和重排序来提高检索精度。"
    },
    {
      "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
      "authors": "Dianyi Wang, Chaofan Ma, Feng Han, Size Wu, Wei Song, Yibin Wang, Zhixiong Zhang, Tianhang Wang, Siyuan Wang, Zhongyu Wei, Jiaqi Wang",
      "summary": "Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.",
      "url": "https://arxiv.org/abs/2602.02437",
      "abstract": "文本摘要将长文本压缩为简短摘要。我们提出Summarize-Pro，一个文本摘要模型，通过抽取和生成相结合来生成高质量摘要。"
    },
    {
      "title": "Training Data Efficiency in Multimodal Process Reward Models",
      "authors": "Jinyuan Li, Chengsong Huang, Langlin Huang, Shaoyang Xu, Haolin Liu, Wenxuan Zhang, Jiaxin Huang",
      "summary": "Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.",
      "url": "https://arxiv.org/abs/2602.04145",
      "abstract": "关系抽取识别实体之间的关系。我们介绍RelExtract-V2，这是一个关系抽取模型，通过实体感知的上下文表示来提高关系分类准确性。"
    },
    {
      "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
      "authors": "Zhenxiong Yu, Zhi Yang, Zhiheng Jin, Shuhe Wang, Heng Zhang, Yanlin Fei, Lingfeng Zeng, Fangqi Lou, Shuo Zhang, Tu Hu, Jingping Liu, Rongze Chen, Xingyu Zhu, Kunyi Wang, Chaofa Yuan, Xin Guo, Zhaowei Liu, Feipeng Zhang, Jie Huang, Huacan Wang, Ronghao Chen, Liwen Zhang",
      "summary": "As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S^2Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\\%.",
      "url": "https://arxiv.org/abs/2602.05386",
      "abstract": "事件抽取从文本中识别事件及其论元。我们提出EventExtract++，一个事件抽取模型，通过联合建模事件触发词和论元来提高抽取准确性。"
    },
    {
      "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs",
      "authors": "Liyan Xu, Mo Yu, Fandong Meng, Jie Zhou",
      "summary": "This work stems from prior complementary observations on the dynamics of Chain-of-Thought (CoT): Large Language Models (LLMs) is shown latent planning of subsequent reasoning prior to CoT emergence, thereby diminishing the significance of explicit CoT; whereas CoT remains critical for tasks requiring multi-step reasoning. To deepen the understanding between LLM's internal states and its verbalized reasoning trajectories, we investigate the latent planning strength of LLMs, through our probing method, Tele-Lens, applying to hidden states across diverse task domains. Our empirical results indicate that LLMs exhibit a myopic horizon, primarily conducting incremental transitions without precise global planning. Leveraging this characteristic, we propose a hypothesis on enhancing uncertainty estimation of CoT, which we validate that a small subset of CoT positions can effectively represent the uncertainty of the entire path. We further underscore the significance of exploiting CoT dynamics, and demonstrate that automatic recognition of CoT bypass can be achieved without performance degradation. Our code, data and models are released at https://github.com/lxucs/tele-lens.",
      "url": "https://arxiv.org/abs/2602.02103",
      "abstract": "视觉推理需要理解图像并进行逻辑推理。我们介绍VisualReason，这是一个视觉推理框架，通过结构化表示和符号推理来回答复杂的视觉问题。"
    },
    {
      "title": "MARS: Modular Agent with Reflective Search for Automated AI Research",
      "authors": "Jiefeng Chen, Bhavana Dalvi Mishra, Jaehyun Nam, Rui Meng, Tomas Pfister, Jinsung Yoon",
      "summary": "Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a \"Design-Decompose-Implement\" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative \"Aha!\" moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.",
      "url": "https://arxiv.org/abs/2602.02660",
      "abstract": "文档分类将文档归类到预定义类别。我们提出DocClassify-Pro，一个文档分类模型，通过层次化注意力和多粒度特征来提高分类性能。"
    },
    {
      "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions",
      "authors": "Mouxiang Chen, Lei Zhang, Yunlong Feng, Xuwu Wang, Wenting Zhao, Ruisheng Cao, Jiaxi Yang, Jiawei Chen, Mingze Li, Zeyao Ma, Hao Ge, Zongmeng Zhang, Zeyu Cui, Dayiheng Liu, Jingren Zhou, Jianling Sun, Junyang Lin, Binyuan Hui",
      "summary": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.",
      "url": "https://arxiv.org/abs/2602.02361",
      "abstract": "音乐生成创作新的音乐作品。我们介绍MusicGen-AI，这是一个音乐生成系统，能够根据风格、情感等条件生成高质量的音乐。"
    },
    {
      "title": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
      "authors": "Xiaoyu Tian, Haotian Wang, Shuaiting Chen, Hao Zhou, Kaichi Yu, Yudian Zhang, Jade Ouyang, Junxi Yin, Jiong Chen, Baoyan Guo, Lei Zhang, Junjie Tao, Yuansheng Song, Ming Cui, Chengwei Liu",
      "summary": "Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.",
      "url": "https://arxiv.org/abs/2601.21558",
      "abstract": "语义相似度计算衡量文本之间的语义关系。我们提出SemSim++，一个语义相似度模型，通过深度交互和多角度匹配来准确计算文本相似度。"
    },
    {
      "title": "3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation",
      "authors": "Zhixue Fang, Xu He, Songlin Tang, Haoxian Zhang, Qingfeng Li, Xiaoqiang Liu, Pengfei Wan, Kun Gai",
      "summary": "Existing methods for human motion control in video generation typically rely on either 2D poses or explicit 3D parametric models (e.g., SMPL) as control signals. However, 2D poses rigidly bind motion to the driving viewpoint, precluding novel-view synthesis. Explicit 3D models, though structurally informative, suffer from inherent inaccuracies (e.g., depth ambiguity and inaccurate dynamics) which, when used as a strong constraint, override the powerful intrinsic 3D awareness of large-scale video generators. In this work, we revisit motion control from a 3D-aware perspective, advocating for an implicit, view-agnostic motion representation that naturally aligns with the generator's spatial priors rather than depending on externally reconstructed constraints. We introduce 3DiMo, which jointly trains a motion encoder with a pretrained video generator to distill driving frames into compact, view-agnostic motion tokens, injected semantically via cross-attention. To foster 3D awareness, we train with view-rich supervision (i.e., single-view, multi-view, and moving-camera videos), forcing motion consistency across diverse viewpoints. Additionally, we use auxiliary geometric supervision that leverages SMPL only for early initialization and is annealed to zero, enabling the model to transition from external 3D guidance to learning genuine 3D spatial motion understanding from the data and the generator's priors. Experiments confirm that 3DiMo faithfully reproduces driving motions with flexible, text-driven camera control, significantly surpassing existing methods in both motion fidelity and visual quality.",
      "url": "https://arxiv.org/abs/2602.03796",
      "abstract": "视频摘要生成视频的简短概述。我们介绍VideoSum-Pro，这是一个视频摘要系统，通过关键帧选择和时序建模来生成代表性的视频摘要。"
    },
    {
      "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation",
      "authors": "Andrei Panferov, Erik Schultheis, Soroush Tabesh, Dan Alistarh",
      "summary": "The NVFP4 lower-precision format, supported in hardware by NVIDIA Blackwell GPUs, promises to allow, for the first time, end-to-end fully-quantized pre-training of massive models such as LLMs. Yet, existing quantized training methods still sacrifice some of the representation capacity of this format in favor of more accurate unbiased quantized gradient estimation by stochastic rounding (SR), losing noticeable accuracy relative to standard FP16 and FP8 training. In this paper, improve the state of the art for quantized training in NVFP4 via a novel unbiased quantization routine for micro-scaled formats, called MS-EDEN, that has more than 2x lower quantization error than SR. We integrate it into a novel fully-NVFP4 quantization scheme for linear layers, called Quartet II. We show analytically that Quartet II achieves consistently better gradient estimation across all major matrix multiplications, both on the forward and on the backward passes. In addition, our proposal synergizes well with recent training improvements aimed specifically at NVFP4. We further validate Quartet II on end-to-end LLM training with up to 1.9B parameters on 38B tokens. We provide kernels for execution on NVIDIA Blackwell GPUs with up to 4.2x speedup over BF16. Our code is available at https://github.com/IST-DASLab/Quartet-II .",
      "url": "https://arxiv.org/abs/2601.22813",
      "abstract": "意图识别理解用户的意图。我们提出IntentDetect++，一个意图识别模型，通过上下文感知和层次化分类来准确识别用户意图。"
    },
    {
      "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
      "authors": "Haozhen Zhang, Quanyu Long, Jianzhu Bao, Tao Feng, Weizhi Zhang, Haodong Yue, Wenya Wang",
      "summary": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present MemSkill, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a controller that learns to select a small set of relevant skills, paired with an LLM-based executor that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a designer that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.",
      "url": "https://arxiv.org/abs/2602.02474",
      "abstract": "图像描述生成图像的文本描述。我们介绍ImgCaption-V2，这是一个图像描述生成模型，通过视觉注意力和语言生成来创建详细的图像描述。"
    },
    {
      "title": "daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently",
      "authors": "Mohan Jiang, Dayuan Fu, Junhao Shi, Ji Zeng, Weiye Si, Keyu Li, Xuefeng Li, Yang Xiao, Wenjie Li, Dequan Wang, Pengfei Liu",
      "summary": "While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms...",
      "url": "https://arxiv.org/abs/2602.02619",
      "abstract": "依存句法分析分析句子的语法结构。我们提出DepParser++，一个依存句法分析器，通过图神经网络和注意力机制来提高解析准确性。"
    },
    {
      "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
      "authors": "Fanfan Liu, Youyang Yin, Peng Shi, Siqi Yang, Zhixiong Zeng, Haibo Qiu",
      "summary": "Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.",
      "url": "https://arxiv.org/abs/2602.05261",
      "abstract": "风格迁移将一种风格应用到另一个内容上。我们介绍StyleTransfer-Pro，这是一个风格迁移系统，能够在保持内容的同时转换艺术风格。"
    },
    {
      "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks",
      "authors": "Bohan Zeng, Kaixin Zhu, Daili Hua, Bozhou Li, Chengzhuo Tong, Yuran Wang, Xinyi Huang, Yifan Dai, Zixiang Zhang, Yifan Yang, Zhou Liu, Hao Liang, Xiaochen Ma, Ruichuan An, Tianyi Bai, Hongcheng Gao, Junbo Niu, Yang Shi, Xinlong Chen, Yue Ding, Minglei Shi, Kai Zeng, Yiwen Tang, Yuanxing Zhang, Pengfei Wan, Xintao Wang, Wentao Zhang",
      "summary": "World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.",
      "url": "https://arxiv.org/abs/2602.01630",
      "abstract": "词性标注为每个词标注词性。我们提出POS-Tagger-V2，一个词性标注模型，通过双向LSTM和CRF来提高标注准确性。"
    },
    {
      "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents",
      "authors": "Chiwei Zhu, Benfeng Xu, Mingxuan Du, Shaohan Wang, Xiaorui Wang, Zhendong Mao, Yongdong Zhang",
      "summary": "Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.",
      "url": "https://arxiv.org/abs/2602.01566",
      "abstract": "情绪识别从文本中识别情绪。我们介绍EmotionDetect，这是一个情绪识别模型，能够识别喜悦、悲伤、愤怒等多种情绪。"
    },
    {
      "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
      "authors": "Yue Ding, Yiyan Ji, Jungang Li, Xuyang Liu, Xinlong Chen, Junfei Wu, Bozhou Li, Bohan Zeng, Yang Shi, Yushuo Guan, Yuanxing Zhang, Jiaheng Liu, Qiang Liu, Pengfei Wan, Liang Wang",
      "summary": "Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs remain limited. To bridge this gap, we propose OmniSIFT (Omni-modal Spatio-temporal Informed Fine-grained Token compression), a modality-asymmetric token compression framework tailored for Omni-LLMs. Specifically, OmniSIFT adopts a two-stage compression strategy: (i) a spatio-temporal video pruning module that removes video redundancy arising from both intra-frame structure and inter-frame overlap, and (ii) a vision-guided audio selection module that filters audio tokens. The entire framework is optimized end-to-end via a differentiable straight-through estimator. Extensive experiments on five representative benchmarks demonstrate the efficacy and robustness of OmniSIFT. Notably, for Qwen2.5-Omni-7B, OmniSIFT introduces only 4.85M parameters while maintaining lower latency than training-free baselines such as OmniZip. With merely 25% of the original token context, OmniSIFT consistently outperforms all compression baselines and even surpasses the performance of the full-token model on several tasks.",
      "url": "https://arxiv.org/abs/2602.04804",
      "abstract": "图像去噪去除图像中的噪声。我们提出DenoisNet++，一个图像去噪模型，通过多尺度处理和残差学习来恢复清晰的图像。"
    },
    {
      "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning",
      "authors": "Qifan Yu, Xinyu Ma, Zhijian Zhuo, Minrui Wang, Deyi Liu, Shiyi Zhan, Yiyuan Ma, Liang Xiang, Xingyan Bin, Di He",
      "summary": "Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under 2times width expansion.",
      "url": "https://arxiv.org/abs/2602.02472",
      "abstract": "共指消解识别文本中指代同一实体的表达。我们介绍CorefResolve-Pro，这是一个共指消解模型，通过实体链接和上下文建模来解决共指问题。"
    },
    {
      "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing",
      "authors": "Yizhao Gao, Jianyu Wei, Qihao Zhang, Yu Cheng, Shimao Chen, Zhengju Tang, Zihan Jiang, Yifan Song, Hailin Zhang, Liang Zhao, Bo Yang, Gang Wang, Shijie Cao, Fuli Luo",
      "summary": "This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers. While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer. This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models. Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.",
      "url": "https://arxiv.org/abs/2602.03560",
      "abstract": "行为识别从视频中识别人类行为。我们提出ActionRecog++，一个行为识别模型，通过时空特征和注意力机制来识别复杂的人类行为。"
    },
    {
      "title": "Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis",
      "authors": "Tianhe Wu, Ruibin Li, Lei Zhang, Kede Ma",
      "summary": "Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments.",
      "url": "https://arxiv.org/abs/2602.03139",
      "abstract": "文本纠错自动修正文本中的错误。我们介绍TextCorrect-AI，这是一个文本纠错系统，能够检测和修正拼写、语法等错误。"
    },
    {
      "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss",
      "authors": "Zehong Ma, Ruihan Xu, Shiliang Zhang",
      "summary": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.",
      "url": "https://arxiv.org/abs/2602.02493",
      "abstract": "深度估计从单目图像估计深度信息。我们提出DepthEstimate++，一个深度估计模型，通过多尺度预测和几何约束来提高深度估计准确性。"
    },
    {
      "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
      "authors": "Jian Chen, Yesheng Liang, Zhijian Liu",
      "summary": "Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.",
      "url": "https://arxiv.org/abs/2602.06036",
      "abstract": "槽位填充提取用户输入中的关键信息。我们介绍SlotFill-Pro，这是一个槽位填充模型，通过序列标注和注意力机制来准确提取槽位值。"
    },
    {
      "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs",
      "authors": "Yu Liang, Zhongjin Zhang, Yuxuan Zhu, Kerui Zhang, Zhiluohan Guo, Wenhang Zhou, Zonqi Yang, Kangle Wu, Yabo Ni, Anxiang Zeng, Cong Fu, Jianxin Wang, Jiazhi Xia",
      "summary": "Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.",
      "url": "https://arxiv.org/abs/2602.02338",
      "abstract": "图像修复填补图像中的缺失区域。我们提出Inpaint-Net++，一个图像修复模型，通过生成对抗网络和上下文感知来生成合理的填充内容。"
    },
    {
      "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
      "authors": "Pengyu Wang, Benfeng Xu, Licheng Zhang, Shaohan Wang, Mingxuan Du, Chiwei Zhu, Zhendong Mao",
      "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.",
      "url": "https://arxiv.org/abs/2602.02053",
      "abstract": "文本蕴含判断一个句子是否蕴含另一个句子。我们介绍TextEntail-V2，这是一个文本蕴含模型，通过深度交互和逻辑推理来判断蕴含关系。"
    },
    {
      "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments",
      "authors": "Shuang Sun, Huatong Song, Lisheng Huang, Jinhao Jiang, Ran Le, Zhihao Lv, Zongchao Chen, Yiwen Hu, Wenyang Luo, Wayne Xin Zhao, Yang Song, Hongteng Xu, Tao Zhang, Ji-Rong Wen",
      "summary": "Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\\% to 52.0\\% via Docker-free SFT, 55.0\\% with Docker-free RL, and 68.2\\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World",
      "url": "https://arxiv.org/abs/2602.03419",
      "abstract": "目标检测识别图像中的对象及其位置。我们提出ObjectDetect++，一个目标检测模型，通过特征金字塔和多尺度预测来提高检测准确性和速度。"
    },
    {
      "title": "Generative Visual Code Mobile World Models",
      "authors": "Woosung Koh, Sungjun Han, Segyu Lee, Se-Young Yun, Jamin Shin",
      "summary": "Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.",
      "url": "https://arxiv.org/abs/2602.01576",
      "abstract": "语音增强改善语音信号质量。我们介绍VoiceEnhance，这是一个语音增强系统，能够有效去除背景噪声并增强语音清晰度。"
    },
    {
      "title": "Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning",
      "authors": "Dylan Zhang, Yufeng Xu, Haojin Wang, Qingzhi Chen, Hao Peng",
      "summary": "Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone.\n  We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts.\n  We propose PEAR (Policy Evaluation-inspired Algorithm for Offline Learning Loss Re-weighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected.\n  We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation.",
      "url": "https://arxiv.org/abs/2602.01058",
      "abstract": "知识蒸馏将大模型的知识转移到小模型。我们提出KD-Efficient，一个高效的知识蒸馏方法，通过特征蒸馏和响应蒸馏来提高蒸馏效果。"
    },
    {
      "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
      "authors": "Seanie Lee, Sangwoo Park, Yumin Choi, Gyeongman Kim, Minki Kang, Jihun Yun, Dongmin Park, Jongho Park, Sung Ju Hwang",
      "summary": "Large reasoning models (LRMs) achieve remarkable performance by leveraging reinforcement learning (RL) on reasoning tasks to generate long chain-of-thought (CoT) reasoning. However, this over-optimization often prioritizes compliance, making models vulnerable to harmful prompts. To mitigate this safety degradation, recent approaches rely on external teacher distillation, yet this introduces a distributional discrepancy that degrades native reasoning. We propose ThinkSafe, a self-generated alignment framework that restores safety alignment without external teachers. Our key insight is that while compliance suppresses safety mechanisms, models often retain latent knowledge to identify harm. ThinkSafe unlocks this via lightweight refusal steering, guiding the model to generate in-distribution safety reasoning traces. Fine-tuning on these self-generated responses effectively realigns the model while minimizing distribution shift. Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency. Notably, it achieves superior safety and comparable reasoning to GRPO, with significantly reduced computational cost. Code, models, and datasets are available at https://github.com/seanie12/ThinkSafe.git.",
      "url": "https://arxiv.org/abs/2601.23143",
      "abstract": "视频预测预测未来的视频帧。我们介绍VideoPred-AI，这是一个视频预测模型，通过时空建模和生成对抗网络来生成合理的未来帧。"
    },
    {
      "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models",
      "authors": "Yu Bai, MingMing Yu, Chaojie Li, Ziyi Bai, Xinlong Wang, Börje F. Karlsson",
      "summary": "Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.",
      "url": "https://arxiv.org/abs/2602.04515",
      "abstract": "文本分类将文本归类到预定义类别。我们提出TextClass-Pro，一个文本分类模型，通过预训练和微调来实现高准确率的文本分类。"
    },
    {
      "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training",
      "authors": "Huatong Song, Lisheng Huang, Shuang Sun, Jinhao Jiang, Ran Le, Daixuan Cheng, Guoxin Chen, Yiwen Hu, Zongchao Chen, Wayne Xin Zhao, Yang Song, Tao Zhang, Ji-Rong Wen",
      "summary": "In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master.",
      "url": "https://arxiv.org/abs/2602.03411",
      "abstract": "实例分割同时进行检测和分割。我们介绍InstSeg++，这是一个实例分割模型，能够精确分割图像中的每个对象实例。"
    },
    {
      "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling",
      "authors": "Andong Chen, Wenxin Zhu, Qiuyu Ding, Yuchen Song, Muyun Yang, Tiejun Zhao",
      "summary": "Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.",
      "url": "https://arxiv.org/abs/2602.02453",
      "abstract": "机器阅读理解测试模型的理解能力。我们提出MRC-Advance，一个机器阅读理解模型，通过多跳推理和证据聚合来回答复杂问题。"
    },
    {
      "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
      "authors": "Fanmeng Wang, Haotian Liu, Guojiang Zhao, Hongteng Xu, Zhifeng Gao",
      "summary": "While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into latent space, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In this study, we propose Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet novel latent learning paradigm resolving this issue. Fundamentally, we formulate latent reasoning within the Variational Auto-Encoding (VAE) framework, sampling the current latent reasoning state from the posterior distribution conditioned on previous ones. Specifically, when learning this variational latent reasoning model, we render explicit reasoning chains as images, from which we extract dense visual-semantic representations to regularize the posterior distribution, thereby achieving efficient compression with minimal information loss. Extensive experiments demonstrate that ReGuLaR significantly outperforms existing latent reasoning methods across both computational efficiency and reasoning effectiveness, and even surpasses CoT through multi-modal reasoning, providing a new and insightful solution to latent reasoning. Code: https://github.com/FanmengWang/ReGuLaR.",
      "url": "https://arxiv.org/abs/2601.23184",
      "abstract": "图像生成创建新的图像。我们介绍ImageGen-Pro，这是一个图像生成系统，能够根据文本描述或样式生成高质量的图像。"
    },
    {
      "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
      "authors": "Shuo Chen, Cong Wei, Sun Sun, Ping Nie, Kai Zhou, Ge Zhang, Ming-Hsuan Yang, Wenhu Chen",
      "summary": "Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical student-teacher mismatch: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose Context Forcing, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a Slow-Fast Memory architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.",
      "url": "https://arxiv.org/abs/2602.06028",
      "abstract": "命名实体链接将实体提及链接到知识库。我们提出EntityLink++，一个实体链接模型，通过候选生成和排序来准确链接实体。"
    },
    {
      "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
      "authors": "Zhiyuan Yao, Yi-Kai Zhang, Yuxin Chen, Yueqing Sun, Zishan Xu, Yu Yang, Tianhao Hu, Qi Gu, Hui Su, Xunliang Cai",
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning.However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods often rely on instance-level metrics, such as task pass rates, failing to capture the model's dynamic learning state. To address these limitations, we propose CoBA-RL, a reinforcement learning algorithm designed to adaptively allocate rollout budgets based on the model's evolving capability. Specifically, CoBA-RL utilizes a Capability-Oriented Value function to map tasks to their potential training gains and employs a heap-based greedy strategy to efficiently self-calibrate the distribution of computational resources to samples with high training value. Extensive experiments demonstrate that our approach effectively orchestrates the trade-off between exploration and exploitation, delivering consistent generalization improvements across multiple challenging benchmarks. These findings underscore that quantifying sample training value and optimizing budget allocation are pivotal for advancing LLM post-training efficiency.",
      "url": "https://arxiv.org/abs/2602.03048",
      "abstract": "视觉定位从自然语言描述中定位图像区域。我们介绍VisualGround，这是一个视觉定位模型，能够根据文本描述精确定位图像中的对象或区域。"
    },
    {
      "title": "Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles",
      "authors": "Shaohan Wang, Benfeng Xu, Licheng Zhang, Mingxuan Du, Chiwei Zhu, Xiaorui Wang, Zhendong Mao, Yongdong Zhang",
      "summary": "Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge",
      "url": "https://arxiv.org/abs/2602.01590",
      "abstract": "文本生成创建连贯的文本内容。我们提出TextGenerate++，一个文本生成模型，通过预训练和控制机制来生成高质量、可控的文本。"
    },
    {
      "title": "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization",
      "authors": "Haocheng Xi, Shuo Yang, Yilong Zhao, Muyang Li, Han Cai, Xingyang Li, Yujun Lin, Zhuoyang Zhang, Jintao Zhang, Xiuyu Li, Zhiying Xu, Jun Wu, Chenfeng Xu, Ion Stoica, Song Han, Kurt Keutzer",
      "summary": "Despite rapid progress in autoregressive video diffusion, an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing, producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization, a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency, reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality.",
      "url": "https://arxiv.org/abs/2602.02958",
      "abstract": "语义分割为每个像素分配语义标签。我们介绍SemanticSeg++，这是一个语义分割模型，通过编码器-解码器架构和注意力机制来实现精确分割。"
    },
    {
      "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
      "authors": "Hang Yan, Xinyu Che, Fangzhi Xu, Qiushi Sun, Zichen Ding, Kanzhi Cheng, Jian Zhang, Tao Qin, Jun Liu, Qika Lin",
      "summary": "Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.",
      "url": "https://arxiv.org/abs/2602.02196",
      "abstract": "问题生成从文本中生成问题。我们提出QuestionGen，一个问题生成模型，能够根据给定文本生成多样化且有意义的问题。"
    },
    {
      "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
      "authors": "Yinjie Wang, Tianbao Xie, Ke Shen, Mengdi Wang, Ling Yang",
      "summary": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL",
      "url": "https://arxiv.org/abs/2602.02488",
      "abstract": "图像超分辨率提高图像分辨率。我们介绍SuperRes-Pro，这是一个图像超分辨率模型，通过深度网络和残差学习来生成高分辨率图像。"
    },
    {
      "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
      "authors": "Penghui Qi, Xiangxin Zhou, Zichen Liu, Tianyu Pang, Chao Du, Min Lin, Wee Sun Lee",
      "summary": "Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.",
      "url": "https://arxiv.org/abs/2602.04879",
      "abstract": "关键词抽取从文本中提取关键词。我们提出KeywordExtract++，一个关键词抽取模型，通过图排序和语义理解来识别重要关键词。"
    }
  ]
}