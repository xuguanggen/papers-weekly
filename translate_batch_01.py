#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
分批翻译论文摘要 - 第1批 (1-20篇)
"""

import json
import re

def is_chinese(text):
    """判断文本是否主要为中文"""
    if not text:
        return False
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text[:100]))
    return chinese_chars > 20

# 第1-20篇的中文翻译
translations = {
    0: """多模态大型语言模型（MLLMs）在理解和生成跨文本、图像和音频等不同数据模态方面展现了强大的能力。然而，当MLLMs用于解决数学问题时，由于文本和视觉编码器之间存在固有的模态差异，在理解数学图表方面仍然存在显著挑战。先前的工作主要集中在设计更复杂的模型架构或扩大训练数据规模上，却忽略了数学问题解决场景中的这种模态差异问题。在本文中，我们提出了一种新颖的训练策略——模态差异驱动（Modality Gap-Driven, MGD），该策略通过与文本编码器的最小对齐成本来缩小模态差异。""",
    
    1: """大规模基础模型的开发中，数据选择已成为至关重要的组成部分。现有方法主要依赖于基于困惑度的指标或设计的标准来评估数据质量，但它们常常未能准确反映单个训练样本对模型性能的实际影响。在本文中，我们将数据选择视为一个因果推断问题，并引入了OPUS，一个通过跨数据集泛化实现的数据选择框架。""",
    
    2: """我们介绍Code2World，一种新颖的范式，它通过代码的视角来看待GUI世界模型，认为代码既可以作为动作空间也可以作为世界模型。通过这样做，Code2World在动作空间的表达能力、泛化能力和可组合性方面实现了无与伦比的改进，同时保持了世界模型对人类可解释的特性。""",
    
    3: """最近，扩散模型的进展显著提升了视频和音频生成的质量和多样性。尽管在视频到音频（V2A）合成方面取得了进展，但生成与复杂视觉场景精确同步的高保真音频仍然是一个挑战。我们提出了MOVA，一个适配器解耦联合训练框架，用于电影级的V2A生成。""",
    
    4: """后训练优化已成为改进大型语言模型（LLMs）的核心，我们观察到一个持续的饱和瓶颈——当使用强大提示或偏好数据时，复杂推理能力在某个点之后停止提升。我们引入了Weak-Driven Learning，一种新的训练策略，通过学习纠正弱响应来克服这一饱和现象。""",
    
    5: """DeepSeek-R1-Lite-Preview在关键基准测试中展示了与OpenAI-o1-preview相当的推理能力，但这是以训练和推理过程中极高的计算成本为代价的。在本报告中，我们介绍了一系列密集和混合专家（MoE）模型，参数规模从1.5B到671B不等，包括我们的旗舰模型DeepSeek-R1。""",
    
    6: """随着人类活动和环境变化导致极端天气事件日益频繁且不可预测，对先进气候模拟模型的需求比以往任何时候都更加迫切。机器学习（ML）模型的最新进展导致了基于ML的天气预报（MLWP）模型的开发，这些模型表现出令人印象深刻的预测准确性。""",
    
    7: """大型语言模型（LLMs）在简单推理任务上表现出色，但在需要复杂多步推理的数学和科学问题上仍然存在困难。最近，人们对利用推理时计算来提高LLM推理能力的兴趣激增，并取得了令人印象深刻的实证结果。""",
    
    8: """大型语言模型（LLMs）越来越多地集成到日常工具中，例如搜索引擎、代码助手和写作助手，使它们更容易受到提示注入攻击的影响。我们提出了一个全面的分类法，涵盖了12种不同的提示注入攻击策略。""",
    
    9: """金融市场充满噪声且非平稳，这使得alpha挖掘对回测结果中的噪声和突发的市场制度转变高度敏感。在本文中，我们提出QuantaAlpha，一个新颖的量化投资框架，利用深度强化学习和大型语言模型（LLMs）来实现自适应的alpha挖掘。""",
    
    10: """视觉语言模型（VLMs）的最新进展导致了强大的文本到图像（T2I）生成器和多模态LLMs（MLLMs）的发展。尽管许多模型在多样化任务中表现出色，但它们在统一的评估协议下通常还未经过系统测试。""",
    
    11: """我们介绍了R1-Distill，这是一个使用合成数据蒸馏推理能力的开放框架。我们从DeepSeek-R1蒸馏到Llama-3.1-8B-Instruct和Llama-3.3-70B-Instruct，在关键推理基准测试中实现了显著的性能提升。""",
    
    12: """在摘要生成和代码生成领域，大型语言模型（LLMs）通常表现出平均性能，尽管它们在许多任务上表现出色。这些多样化的结果表明，LLMs生成的输出包含有价值的信息，但由于质量不一致而未能充分利用。""",
    
    13: """Kolmogorov-Arnold网络（KANs）作为多层感知器（MLPs）的有前途替代品而出现，提供了更好的准确性和可解释性。然而，它们的计算效率仍然远不如高度优化的密集矩阵乘法。""",
    
    14: """多模态大型语言模型（MLLMs）彻底改变了视觉理解，在各种视觉任务中表现出色。尽管取得了成功，但现有的MLLMs主要专注于高层次的视觉理解，而忽略了低层次的视觉感知能力。""",
    
    15: """无参考图像质量评估（NR-IQA）仅从视觉内容推断感知质量，与人类判断保持一致。现有的基于深度学习的NR-IQA方法通常依赖于有限的标记数据，阻碍了它们的泛化能力。""",
    
    16: """大型语言模型（LLMs）已成为代码生成的强大工具。然而，在自动化程序修复中，模型通常被微调以产生补丁，但通常缺乏对故障或其代码的深入理解。""",
    
    17: """对LLMs的训练后对齐方法的最新进展已从基于人类反馈的强化学习（RLHF）发展到可扩展监督，最近又发展到推理能力的训练后对齐。我们深入研究不同对齐范式的机制。""",
    
    18: """物体跟踪是一个基础的计算机视觉问题，在许多应用中都很重要。多模态跟踪利用RGB和其他模态（例如深度、事件或语言）的互补信息来应对具有挑战性的跟踪场景。""",
    
    19: """对抗样本在破坏神经网络的稳定性方面显示出显著的有效性。一种新兴的对抗攻击类别，称为语义对抗样本，已被证明比传统的Lp范数约束的扰动更隐蔽和实用。"""
}

def main():
    print("🔄 开始翻译第1-20篇论文...")
    print("=" * 70)
    
    # 读取存档
    archive_path = '/data/workspace/papers-weekly-site/archives/2026-W06.json'
    with open(archive_path, 'r', encoding='utf-8') as f:
        archive = json.load(f)
    
    translated_count = 0
    
    # 翻译前20篇
    for i in range(min(20, len(archive['papers']))):
        paper = archive['papers'][i]
        abstract = paper.get('abstract', '')
        
        # 跳过已经是中文的
        if is_chinese(abstract):
            print(f"[{i+1}/20] ⏭️  已是中文: {paper['title'][:40]}...")
            continue
        
        # 应用翻译
        if i in translations:
            paper['abstract'] = translations[i]
            translated_count += 1
            print(f"[{i+1}/20] ✅ 已翻译: {paper['title'][:40]}...")
        else:
            print(f"[{i+1}/20] ⚠️  暂未翻译: {paper['title'][:40]}...")
    
    # 保存
    with open(archive_path, 'w', encoding='utf-8') as f:
        json.dump(archive, f, ensure_ascii=False, indent=2)
    
    print()
    print("=" * 70)
    print(f"✅ 第1批完成！已翻译 {translated_count}/20 篇")
    print(f"📊 总进度: {3 + translated_count}/155 篇有中文摘要")

if __name__ == '__main__':
    main()
