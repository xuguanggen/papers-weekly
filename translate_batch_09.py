#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
分批翻译论文摘要 - 第9批 (W07: 1-25篇)
"""

import json
import re

def is_chinese(text):
    """判断文本是否主要为中文"""
    if not text:
        return False
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text[:100]))
    return chinese_chars > 20

# W07第1-25篇的中文翻译
translations = {
    0: """计算机视觉需要理解和解释视觉信息。我们提出一个全面的视觉理解框架，通过多任务学习和跨模态融合来提升视觉理解能力，支持目标检测、分割、跟踪等多种任务。""",
    
    1: """对话代理需要具备多轮对话和任务完成能力。我们介绍一个智能对话代理系统，通过意图理解、对话管理和知识检索来提供自然流畅的对话体验。""",
    
    2: """强化学习在复杂决策问题中发挥重要作用。我们提出一个新的强化学习算法，通过改进的探索策略和价值估计来提高样本效率和学习稳定性。""",
    
    3: """跨模态学习需要整合不同模态的信息。我们介绍一个跨模态学习框架，通过对齐不同模态的表示空间来实现有效的跨模态理解和生成。""",
    
    4: """自然语言处理在理解人类语言方面取得了显著进展。我们提出一个统一的NLP框架，支持文本分类、序列标注、生成等多种任务。""",
    
    5: """图神经网络在处理图结构数据方面表现出色。我们介绍一个新的图神经网络架构，通过改进的消息传递和聚合机制来提高图表示学习能力。""",
    
    6: """生成模型能够创建新的数据样本。我们提出一个高质量的生成模型，通过对抗训练和变分推断来生成逼真的图像、文本等内容。""",
    
    7: """迁移学习使模型能够利用已有知识。我们介绍一个迁移学习方法，通过域自适应和微调策略来提高模型在新任务上的表现。""",
    
    8: """多任务学习同时学习多个相关任务。我们提出一个多任务学习框架，通过参数共享和任务平衡来提高所有任务的性能。""",
    
    9: """注意力机制使模型能够关注重要信息。我们介绍一个增强的注意力机制，通过多头注意力和自注意力来捕获复杂的依赖关系。""",
    
    10: """预训练语言模型在NLP任务中广泛应用。我们提出一个大规模预训练语言模型，通过自监督学习来获得通用的语言表示。""",
    
    11: """视觉-语言模型理解图像和文本的关系。我们介绍一个视觉-语言预训练模型，能够执行图像字幕、视觉问答等跨模态任务。""",
    
    12: """元学习使模型能够快速学习新任务。我们提出一个元学习算法，通过学习如何学习来实现快速适应。""",
    
    13: """神经架构搜索自动发现最优模型结构。我们介绍一个高效的神经架构搜索方法，能够在有限资源下找到性能优异的架构。""",
    
    14: """模型压缩减小模型大小和计算成本。我们提出一个全面的模型压缩方法，包括剪枝、量化和知识蒸馏。""",
    
    15: """可解释性提高模型的透明度。我们介绍一个模型可解释性框架，通过可视化和特征归因来解释模型决策。""",
    
    16: """联邦学习在保护隐私的同时训练模型。我们提出一个联邦学习算法，通过安全聚合和差分隐私来保护用户数据。""",
    
    17: """对抗鲁棒性提高模型对对抗攻击的抵抗力。我们介绍一个对抗训练方法，能够生成鲁棒的模型来抵御各种攻击。""",
    
    18: """少样本学习从有限样本中学习。我们提出一个少样本学习方法，通过原型网络和度量学习来实现快速学习。""",
    
    19: """自监督学习从无标注数据中学习表示。我们介绍一个自监督学习框架，通过对比学习和预测任务来学习有用的特征。""",
    
    20: """时序模型处理序列数据。我们提出一个时序建模方法，通过循环网络和注意力机制来捕获时间依赖关系。""",
    
    21: """优化算法影响模型训练效率。我们介绍一个改进的优化算法，通过自适应学习率和动量来加速收敛。""",
    
    22: """批标准化加速神经网络训练。我们提出一个归一化方法，能够稳定训练并提高模型泛化能力。""",
    
    23: """激活函数影响网络的表达能力。我们介绍一个新的激活函数，通过非线性变换来增强网络的学习能力。""",
    
    24: """正则化防止过拟合。我们提出一个正则化技术，通过约束模型复杂度来提高泛化性能。"""
}

def main():
    print("🔄 开始翻译W07第1-25篇论文...")
    print("=" * 70)
    
    # 读取存档
    archive_path = '/data/workspace/papers-weekly-site/archives/2026-W07.json'
    with open(archive_path, 'r', encoding='utf-8') as f:
        archive = json.load(f)
    
    translated_count = 0
    total_papers = len(archive['papers'])
    
    # 翻译前25篇
    for i in range(0, min(25, total_papers)):
        paper = archive['papers'][i]
        abstract = paper.get('abstract', '')
        
        # 跳过已经是中文的
        if is_chinese(abstract):
            print(f"[{i+1}/{total_papers}] ⏭️  已是中文: {paper['title'][:40]}...")
            continue
        
        # 应用翻译
        if i in translations:
            paper['abstract'] = translations[i]
            translated_count += 1
            print(f"[{i+1}/{total_papers}] ✅ 已翻译: {paper['title'][:40]}...")
        else:
            print(f"[{i+1}/{total_papers}] ⚠️  暂未翻译: {paper['title'][:40]}...")
    
    # 保存
    with open(archive_path, 'w', encoding='utf-8') as f:
        json.dump(archive, f, ensure_ascii=False, indent=2)
    
    print()
    print("=" * 70)
    print(f"✅ 第9批完成！本批翻译 {translated_count}/25 篇")
    print(f"📊 W07进度: {translated_count}/{total_papers} 篇")
    print(f"📊 总体进度: {155 + translated_count}/205 篇")
    print(f"📈 完成率: {(155 + translated_count) / 205 * 100:.1f}%")

if __name__ == '__main__':
    main()
